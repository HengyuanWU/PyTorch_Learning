{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Transformer 实验与调参手册 (AG NEWS)\n",
        "\n",
        "## 目录\n",
        "- [环境准备](#环境准备)\n",
        "- [单次 Baseline 训练](#单次-Baseline-训练)\n",
        "- [超参数网格搜索](#超参数网格搜索)\n",
        "- [结果汇总表](#结果汇总表)\n",
        "- [曲线可视化](#曲线可视化)\n",
        "- [拆零件小实验](#拆零件小实验)\n",
        "- [Attention 可视化](#Attention-可视化)\n",
        "- [结论总结](#结论总结)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 环境准备\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "项目根目录: c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\n",
            "输出目录: c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\outputs\\transformer\n",
            "数据目录: c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\data\n",
            "PyTorch 版本: 2.5.1\n",
            "CUDA 可用: False\n",
            "torchtext 版本: 0.6.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_9440\\202672887.py:38: UserWarning: torchtext版本(0.6.0)与推荐版本(0.14.0)不一致\n",
            "  warnings.warn(f\"{module_name}版本({module.__version__})与推荐版本({required_version})不一致\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torchvision 版本: 0.20.1\n",
            "已成功导入 torchtext，版本: 0.6.0\n",
            "✓ 所有项目模块导入成功\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_9440\\202672887.py:38: UserWarning: torchvision版本(0.20.1)与推荐版本(0.14.0)不一致\n",
            "  warnings.warn(f\"{module_name}版本({module.__version__})与推荐版本({required_version})不一致\")\n"
          ]
        }
      ],
      "source": [
        "# 环境检查与配置\n",
        "import os, sys\n",
        "from pathlib import Path\n",
        "import importlib\n",
        "import torch\n",
        "import warnings\n",
        "\n",
        "# 设置项目根目录路径\n",
        "project_root = os.path.abspath('..')\n",
        "if project_root not in sys.path:\n",
        "    sys.path.insert(0, project_root)\n",
        "os.environ[\"PYTHONPATH\"] = project_root\n",
        "\n",
        "# 创建必要的目录\n",
        "output_dir = Path(project_root) / 'outputs' / 'transformer'\n",
        "output_dir.mkdir(parents=True, exist_ok=True)\n",
        "data_dir = Path(project_root) / 'data'\n",
        "data_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 检查关键模块与版本\n",
        "print(f\"项目根目录: {project_root}\")\n",
        "print(f\"输出目录: {output_dir}\")\n",
        "print(f\"数据目录: {data_dir}\")\n",
        "print(f\"PyTorch 版本: {torch.__version__}\")\n",
        "print(f\"CUDA 可用: {torch.cuda.is_available()}\")\n",
        "\n",
        "# 检查必要的依赖\n",
        "dependencies = {\n",
        "    'torchtext': '0.14.0',\n",
        "    'torchvision': '0.14.0'\n",
        "}\n",
        "\n",
        "for module_name, required_version in dependencies.items():\n",
        "    try:\n",
        "        module = importlib.import_module(module_name)\n",
        "        print(f\"{module_name} 版本: {module.__version__}\")\n",
        "        if module.__version__ != required_version:\n",
        "            warnings.warn(f\"{module_name}版本({module.__version__})与推荐版本({required_version})不一致\")\n",
        "    except ImportError:\n",
        "        print(f\"未安装{module_name}，请运行: pip install {module_name}=={required_version}\")\n",
        "\n",
        "# 检查项目模块导入\n",
        "try:\n",
        "    from utils import text_dataloader, dataloader\n",
        "    from train import train_transformer\n",
        "    from models import transformer\n",
        "    print(\"✓ 所有项目模块导入成功\")\n",
        "except Exception as e:\n",
        "    print(f\"项目模块导入错误: {e}\")\n",
        "    print(\"请确保utils/__init__.py正确配置了PROJECT_ROOT\")\n",
        "\n",
        "# Jupyter notebook相关配置\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 导入必要模块\n",
        "import torch\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import subprocess\n",
        "import json\n",
        "import sys\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch版本: 2.5.1\n",
            "torchtext版本: 0.6.0\n",
            "torchvision版本: 0.20.1\n",
            "seaborn已安装\n",
            "seaborn版本: 0.13.2\n",
            "\n",
            "⚠️ 检测到以下兼容性问题:\n",
            "- PyTorch版本建议使用1.x.x系列，当前为2.5.1\n",
            "- torchtext版本(0.6.0)与PyTorch版本(2.5.1)不兼容\n",
            "\n",
            "建议修复方案:\n",
            "- 针对PyTorch 1.13.x: pip install torchtext==0.14.0\n",
            "- 针对PyTorch 2.x: pip install torchtext>=0.15.0\n",
            "- 如遇内存溢出: 运行根目录下的clear_cache.py脚本\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_9440\\3406789192.py:41: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
            "  import pkg_resources\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 添加兼容性检查工具，用于确认环境兼容性并提供修复建议\n",
        "\n",
        "def check_compatibility():\n",
        "    \"\"\"检查环境兼容性并提供修复建议\"\"\"\n",
        "    compatibility_issues = []\n",
        "    \n",
        "    # 检查PyTorch版本\n",
        "    try:\n",
        "        import torch\n",
        "        print(f\"PyTorch版本: {torch.__version__}\")\n",
        "        if torch.__version__.split('.')[0] != '1':\n",
        "            compatibility_issues.append(f\"PyTorch版本建议使用1.x.x系列，当前为{torch.__version__}\")\n",
        "    except ImportError:\n",
        "        compatibility_issues.append(\"未安装PyTorch\")\n",
        "    \n",
        "    # 检查torchtext\n",
        "    try:\n",
        "        import torchtext\n",
        "        print(f\"torchtext版本: {torchtext.__version__}\")\n",
        "        \n",
        "        # 检查与PyTorch版本的兼容性\n",
        "        if torch.__version__.split('.')[0] != torchtext.__version__.split('.')[0]:\n",
        "            compatibility_issues.append(f\"torchtext版本({torchtext.__version__})与PyTorch版本({torch.__version__})不兼容\")\n",
        "            \n",
        "    except ImportError:\n",
        "        compatibility_issues.append(\"未安装torchtext，请运行: pip install torchtext==0.14.0\")\n",
        "    \n",
        "    # 检查torchvision\n",
        "    try:\n",
        "        import torchvision\n",
        "        print(f\"torchvision版本: {torchvision.__version__}\")\n",
        "    except ImportError:\n",
        "        compatibility_issues.append(\"未安装torchvision\")\n",
        "    \n",
        "    # 检查seaborn (用于可视化)\n",
        "    try:\n",
        "        import seaborn\n",
        "        print(f\"seaborn已安装\")\n",
        "        # 尝试获取版本信息而不使用__version__\n",
        "        try:\n",
        "            import pkg_resources\n",
        "            seaborn_version = pkg_resources.get_distribution(\"seaborn\").version\n",
        "            print(f\"seaborn版本: {seaborn_version}\")\n",
        "        except:\n",
        "            print(\"无法获取seaborn版本\")\n",
        "    except ImportError:\n",
        "        compatibility_issues.append(\"未安装seaborn，可视化功能可能受限\")\n",
        "    \n",
        "    # 显示总结\n",
        "    if compatibility_issues:\n",
        "        print(\"\\n⚠️ 检测到以下兼容性问题:\")\n",
        "        for issue in compatibility_issues:\n",
        "            print(f\"- {issue}\")\n",
        "        \n",
        "        print(\"\\n建议修复方案:\")\n",
        "        print(\"- 针对PyTorch 1.13.x: pip install torchtext==0.14.0\")\n",
        "        print(\"- 针对PyTorch 2.x: pip install torchtext>=0.15.0\")\n",
        "        print(\"- 如遇内存溢出: 运行根目录下的clear_cache.py脚本\")\n",
        "        return False\n",
        "    else:\n",
        "        print(\"\\n✅ 环境兼容性检查通过！\")\n",
        "        return True\n",
        "\n",
        "# 运行兼容性检查\n",
        "check_compatibility()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 单次 Baseline 训练\n",
        "\n",
        "首先运行一次基础训练，确保代码无错误且能成功训练。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "现在尝试直接在notebook中运行训练，以便查看实时训练输出...\n",
            "[Transformer] Using device: cpu\n",
            "使用本地缓存: C:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\data\\ag_news\\train.csv\n",
            "构建词表...\n",
            "词表大小: 158735\n",
            "处理训练集...\n",
            "使用本地缓存: C:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\data\\ag_news\\train.csv\n",
            "使用本地缓存: C:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\data\\ag_news\\test.csv\n",
            "构建词表...\n",
            "词表大小: 158735\n",
            "处理测试集...\n",
            "词表大小: 158735, 类别数: 4\n",
            "\n",
            "=== Epoch 1 ===\n",
            "[6400/120000] loss: 1.4877\n"
          ]
        }
      ],
      "source": [
        "# 在notebook中直接运行Transformer训练（将在notebook中显示训练输出）\n",
        "from train.train_transformer import run_transformer_training\n",
        "\n",
        "print(\"\\n现在尝试直接在notebook中运行训练，以便查看实时训练输出...\")\n",
        "\n",
        "# 使用当前的Python解释器\n",
        "python_executable = sys.executable\n",
        "print(f\"使用Python解释器: {python_executable}\")\n",
        "\n",
        "# 运行训练，可以看到每个epoch的训练过程和loss输出\n",
        "history = run_transformer_training(\n",
        "    epochs=5,\n",
        "    train_batch_size=64, \n",
        "    val_batch_size=64,\n",
        "    lr=1e-3,\n",
        "    embed_dim=128,\n",
        "    num_heads=4,\n",
        "    output_dir=str(output_dir)\n",
        ")\n",
        "\n",
        "# 显示训练历史数据\n",
        "print(\"\\n训练历史:\")\n",
        "for epoch, (val_loss, val_acc) in enumerate(history, 1):\n",
        "    print(f\"Epoch {epoch}: Val loss: {val_loss:.4f}, Val acc: {val_acc:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 超参数网格搜索\n",
        "\n",
        "定义一组系统化的超参数组合，进行网格搜索实验。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 定义超参数网格\n",
        "grid = [\n",
        "    {\"embed_dim\": d, \"num_heads\": h, \"lr\": lr}\n",
        "    for d, h in [(64, 2), (128, 4), (256, 8)]\n",
        "    for lr in [5e-4, 1e-3]\n",
        "]\n",
        "results = []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 函数用于解析输出中的验证准确率\n",
        "def parse_output(output_str):\n",
        "    lines = output_str.split('\\n')\n",
        "    val_acc = None\n",
        "    for line in lines:\n",
        "        if \"Val loss\" in line:\n",
        "            parts = line.split(',')\n",
        "            if len(parts) > 1:\n",
        "                acc_part = parts[1].strip()\n",
        "                val_acc = float(acc_part.replace('Acc: ', '').replace('%', ''))\n",
        "    return val_acc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 确保 PYTHONPATH 和 sys.path 正确设置\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import time\n",
        "\n",
        "project_root = os.path.abspath('..')\n",
        "if project_root not in sys.path:\n",
        "    sys.path.insert(0, project_root)\n",
        "os.environ[\"PYTHONPATH\"] = project_root\n",
        "\n",
        "# 确保输出目录存在\n",
        "output_dir = Path(project_root) / 'outputs' / 'transformer'\n",
        "output_dir.mkdir(parents=True, exist_ok=True)\n",
        "print(f\"输出目录: {output_dir}\")\n",
        "\n",
        "# 确保数据目录存在\n",
        "data_dir = Path(project_root) / 'data'\n",
        "data_dir.mkdir(parents=True, exist_ok=True)\n",
        "print(f\"数据目录: {data_dir}\")\n",
        "\n",
        "# 获取当前 Python 解释器路径\n",
        "python_executable = sys.executable\n",
        "print(f\"使用 Python 解释器: {python_executable}\")\n",
        "\n",
        "# 确保训练脚本存在\n",
        "train_script = os.path.join(project_root, \"train\", \"train_transformer.py\")\n",
        "if not os.path.exists(train_script):\n",
        "    raise FileNotFoundError(f\"训练脚本不存在: {train_script}\")\n",
        "print(f\"训练脚本: {train_script}\")\n",
        "\n",
        "# 循环执行每个超参数组合的实验\n",
        "for i, params in enumerate(grid):\n",
        "    print(f\"\\n实验 {i+1}/{len(grid)}: {params}\")\n",
        "    \n",
        "    try:\n",
        "        # 为每个实验创建唯一的输出目录\n",
        "        exp_dir = output_dir / f\"exp_{params['embed_dim']}_{params['num_heads']}_{params['lr']}\"\n",
        "        exp_dir.mkdir(parents=True, exist_ok=True)\n",
        "        \n",
        "        # 构建命令\n",
        "        cmd = [\n",
        "            python_executable, \n",
        "            train_script,\n",
        "            \"--epochs\", \"3\",\n",
        "            \"--batch-size\", \"64\",\n",
        "            \"--embed-dim\", str(params['embed_dim']),\n",
        "            \"--num-heads\", str(params['num_heads']),\n",
        "            \"--lr\", str(params['lr']),\n",
        "            \"--output-dir\", str(exp_dir)\n",
        "        ]\n",
        "        \n",
        "        # 设置环境变量，确保脚本可以找到项目模块\n",
        "        env = os.environ.copy()\n",
        "        env[\"PYTHONPATH\"] = project_root\n",
        "        \n",
        "        # 执行命令并捕获输出\n",
        "        print(f\"执行命令: {' '.join(cmd)}\")\n",
        "        process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, env=env)\n",
        "        stdout, stderr = process.communicate()\n",
        "        \n",
        "        if process.returncode != 0:\n",
        "            print(f\"警告: 命令执行失败，返回码 {process.returncode}\")\n",
        "            print(f\"错误信息: {stderr[:500]}...\")\n",
        "            val_acc = None\n",
        "        else:\n",
        "            # 解析验证准确率\n",
        "            val_acc = parse_output(stdout)\n",
        "            \n",
        "        # 将结果添加到列表\n",
        "        result = params.copy()\n",
        "        result['val_acc'] = val_acc\n",
        "        results.append(result)\n",
        "        \n",
        "        if val_acc is not None:\n",
        "            print(f\"验证准确率: {val_acc:.2f}%\")\n",
        "        else:\n",
        "            print(\"无法获取验证准确率\")\n",
        "            \n",
        "        # 保存当前结果（即使有错误也保存部分结果）\n",
        "        results_df = pd.DataFrame(results)\n",
        "        results_df.to_csv(output_dir / \"grid_search_results.csv\", index=False)\n",
        "        \n",
        "        # 短暂暂停，避免系统资源过度使用\n",
        "        time.sleep(1)\n",
        "    \n",
        "    except Exception as e:\n",
        "        print(f\"实验执行出错: {e}\")\n",
        "        # 添加一个包含错误信息的结果\n",
        "        results.append({\n",
        "            **params,\n",
        "            'val_acc': None,\n",
        "            'error': str(e)\n",
        "        })\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 结果汇总表\n",
        "\n",
        "将网格搜索结果整理成 DataFrame 并排序。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>embed_dim</th>\n",
              "      <th>num_heads</th>\n",
              "      <th>lr</th>\n",
              "      <th>val_acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>64</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>64</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>128</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>128</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>256</td>\n",
              "      <td>8</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>256</td>\n",
              "      <td>8</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   embed_dim  num_heads      lr val_acc\n",
              "0         64          2  0.0005    None\n",
              "1         64          2  0.0010    None\n",
              "2        128          4  0.0005    None\n",
              "3        128          4  0.0010    None\n",
              "4        256          8  0.0005    None\n",
              "5        256          8  0.0010    None"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 转换为 DataFrame\n",
        "df = pd.DataFrame(results)\n",
        "\n",
        "# 按验证准确率降序排序\n",
        "df_sorted = df.sort_values(by='val_acc', ascending=False)\n",
        "display(df_sorted)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 曲线可视化\n",
        "\n",
        "绘制超参数对性能影响的曲线图。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 确保输出目录存在\n",
        "from pathlib import Path\n",
        "output_dir = Path(project_root) / 'outputs' / 'transformer'\n",
        "output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 确保可视化目录存在\n",
        "viz_dir = output_dir / 'viz'\n",
        "viz_dir.mkdir(parents=True, exist_ok=True)\n",
        "print(f\"可视化输出目录: {viz_dir}\")\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# 检查数据是否存在有效值\n",
        "if len(df[df[\"val_acc\"].notnull()]) == 0:\n",
        "    plt.text(0.5, 0.5, \"没有有效的实验数据\", \n",
        "             horizontalalignment='center', verticalalignment='center',\n",
        "             fontsize=18, transform=plt.gca().transAxes)\n",
        "    plt.title(\"数据缺失，无法生成图表\")\n",
        "else:\n",
        "    # 1. Embedding维度对准确率影响\n",
        "    sns.lineplot(data=df, x=\"embed_dim\", y=\"val_acc\", hue=\"num_heads\", style=\"lr\")\n",
        "    plt.title(\"Embedding 维度 / Head 数 / LR 对准确率影响\")\n",
        "    plt.xlabel(\"Embedding 维度\")\n",
        "    plt.ylabel(\"验证准确率 (%)\")\n",
        "    plt.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "# 保存图像\n",
        "output_file = viz_dir / 'param_impact.png'\n",
        "plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
        "print(f\"图像已保存: {output_file}\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. 学习率对不同模型规模的影响\n",
        "g = sns.catplot(\n",
        "    data=df, x=\"lr\", y=\"val_acc\", \n",
        "    col=\"embed_dim\", hue=\"num_heads\",\n",
        "    kind=\"bar\", height=5, aspect=0.8\n",
        ")\n",
        "g.set_axis_labels(\"学习率\", \"验证准确率 (%)\")\n",
        "g.set_titles(\"Embedding维度: {col_name}\")\n",
        "plt.savefig(output_dir / 'lr_impact.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 拆零件小实验\n",
        "\n",
        "进行6种结构变体实验，观察各组件对模型性能的影响。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 定义消融实验列表\n",
        "ablations = [\n",
        "    \"no_pe\",        # 关闭位置编码\n",
        "    \"single_head\",  # 只用单头注意力\n",
        "    \"no_ffn\",       # 移除前馈网络\n",
        "    \"freeze_emb\",   # 冻结embedding\n",
        "    \"no_dropout\",   # 关闭dropout\n",
        "    \"clip_grad\"     # 梯度裁剪\n",
        "]\n",
        "\n",
        "# 获取最佳配置作为基准\n",
        "best_config = df_sorted.iloc[0].to_dict()\n",
        "embed_dim = int(best_config['embed_dim'])\n",
        "num_heads = int(best_config['num_heads'])\n",
        "lr = best_config['lr']\n",
        "\n",
        "ablation_results = []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "使用 Python 解释器: c:\\Users\\WHY\\anaconda3\\envs\\dl\\python.exe\n",
            "运行基准模型（无消融）...\n",
            "警告: 命令执行失败，返回码 1\n",
            "错误信息: Traceback (most recent call last):\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 197, in <module>\n",
            "    run_transformer_training() \n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 113, in run_transformer_training\n",
            "    train_loader, val_loader, vocab_size, num_classes = get_ag_news_loaders(\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 47, in get_ag_news_loaders\n",
            "    train...\n",
            "基准模型验证准确率: 0.00%\n"
          ]
        }
      ],
      "source": [
        "# 确保 project_root 已定义\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "if 'project_root' not in locals():\n",
        "    project_root = os.path.abspath('..')\n",
        "    if project_root not in sys.path:\n",
        "        sys.path.insert(0, project_root)\n",
        "    os.environ[\"PYTHONPATH\"] = project_root\n",
        "\n",
        "# 确保输出目录存在\n",
        "output_dir = Path(project_root) / 'outputs' / 'transformer'\n",
        "output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 获取 Python 解释器路径\n",
        "python_executable = sys.executable\n",
        "print(f\"使用 Python 解释器: {python_executable}\")\n",
        "\n",
        "# 先运行一次基础模型（无消融）作为对照\n",
        "print(\"运行基准模型（无消融）...\")\n",
        "try:\n",
        "    cmd = [\n",
        "        python_executable, \n",
        "        os.path.join(project_root, \"train\", \"train_transformer.py\"),\n",
        "        \"--epochs\", \"3\",\n",
        "        \"--batch-size\", \"64\",\n",
        "        \"--embed-dim\", str(embed_dim),\n",
        "        \"--num-heads\", str(num_heads),\n",
        "        \"--lr\", str(lr)\n",
        "    ]\n",
        "    # 设置环境变量，确保脚本可以找到项目模块\n",
        "    env = os.environ.copy()\n",
        "    env[\"PYTHONPATH\"] = project_root\n",
        "    \n",
        "    process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, env=env)\n",
        "    stdout, stderr = process.communicate()\n",
        "    \n",
        "    if process.returncode != 0:\n",
        "        print(f\"警告: 命令执行失败，返回码 {process.returncode}\")\n",
        "        print(f\"错误信息: {stderr[:500]}...\")\n",
        "        val_acc = 0\n",
        "    else:\n",
        "        val_acc = parse_output(stdout)\n",
        "        if val_acc is None:\n",
        "            val_acc = 0\n",
        "            print(\"无法解析验证准确率，使用默认值 0\")\n",
        "    \n",
        "    ablation_results.append({\n",
        "        \"ablation\": \"baseline\",\n",
        "        \"description\": \"基准模型（无消融）\",\n",
        "        \"val_acc\": val_acc\n",
        "    })\n",
        "    print(f\"基准模型验证准确率: {val_acc:.2f}%\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"运行基准模型时出错: {e}\")\n",
        "    # 添加一个包含默认值的结果，以便后续代码可以继续执行\n",
        "    ablation_results.append({\n",
        "        \"ablation\": \"baseline\",\n",
        "        \"description\": \"基准模型（无消融）\",\n",
        "        \"val_acc\": 0\n",
        "    })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "运行消融实验: no_pe - 关闭位置编码\n",
            "警告: 命令执行失败，返回码 1\n",
            "错误信息: Traceback (most recent call last):\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 197, in <module>\n",
            "    run_transformer_training() \n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 113, in run_transformer_training\n",
            "    train_loader, val_loader, vocab_size, num_classes = get_ag_news_loaders(\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 47, in get_ag_news_loaders\n",
            "    train...\n",
            "验证准确率: 0.00%\n",
            "\n",
            "运行消融实验: single_head - 只用单头注意力\n",
            "警告: 命令执行失败，返回码 1\n",
            "错误信息: Traceback (most recent call last):\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 197, in <module>\n",
            "    run_transformer_training() \n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 113, in run_transformer_training\n",
            "    train_loader, val_loader, vocab_size, num_classes = get_ag_news_loaders(\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 47, in get_ag_news_loaders\n",
            "    train...\n",
            "验证准确率: 0.00%\n",
            "\n",
            "运行消融实验: no_ffn - 移除前馈网络\n",
            "警告: 命令执行失败，返回码 1\n",
            "错误信息: Traceback (most recent call last):\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 197, in <module>\n",
            "    run_transformer_training() \n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 113, in run_transformer_training\n",
            "    train_loader, val_loader, vocab_size, num_classes = get_ag_news_loaders(\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 47, in get_ag_news_loaders\n",
            "    train...\n",
            "验证准确率: 0.00%\n",
            "\n",
            "运行消融实验: freeze_emb - 冻结embedding\n",
            "警告: 命令执行失败，返回码 1\n",
            "错误信息: Traceback (most recent call last):\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 197, in <module>\n",
            "    run_transformer_training() \n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 113, in run_transformer_training\n",
            "    train_loader, val_loader, vocab_size, num_classes = get_ag_news_loaders(\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 47, in get_ag_news_loaders\n",
            "    train...\n",
            "验证准确率: 0.00%\n",
            "\n",
            "运行消融实验: no_dropout - 关闭dropout\n",
            "警告: 命令执行失败，返回码 1\n",
            "错误信息: Traceback (most recent call last):\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 197, in <module>\n",
            "    run_transformer_training() \n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 113, in run_transformer_training\n",
            "    train_loader, val_loader, vocab_size, num_classes = get_ag_news_loaders(\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 47, in get_ag_news_loaders\n",
            "    train...\n",
            "验证准确率: 0.00%\n",
            "\n",
            "运行消融实验: clip_grad - 梯度裁剪\n",
            "警告: 命令执行失败，返回码 1\n",
            "错误信息: Traceback (most recent call last):\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 197, in <module>\n",
            "    run_transformer_training() \n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 113, in run_transformer_training\n",
            "    train_loader, val_loader, vocab_size, num_classes = get_ag_news_loaders(\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 47, in get_ag_news_loaders\n",
            "    train...\n",
            "验证准确率: 0.00%\n"
          ]
        }
      ],
      "source": [
        "# 运行各种消融实验\n",
        "descriptions = {\n",
        "    \"no_pe\": \"关闭位置编码\",\n",
        "    \"single_head\": \"只用单头注意力\",\n",
        "    \"no_ffn\": \"移除前馈网络\",\n",
        "    \"freeze_emb\": \"冻结embedding\",\n",
        "    \"no_dropout\": \"关闭dropout\",\n",
        "    \"clip_grad\": \"梯度裁剪\"\n",
        "}\n",
        "\n",
        "for ablation in ablations:\n",
        "    print(f\"\\n运行消融实验: {ablation} - {descriptions[ablation]}\")\n",
        "    try:\n",
        "        cmd = [\n",
        "            python_executable, \n",
        "            os.path.join(project_root, \"train\", \"train_transformer.py\"),\n",
        "            \"--epochs\", \"3\",\n",
        "            \"--batch-size\", \"64\",\n",
        "            \"--embed-dim\", str(embed_dim),\n",
        "            \"--num-heads\", str(num_heads),\n",
        "            \"--lr\", str(lr),\n",
        "            \"--ablation\", ablation\n",
        "        ]\n",
        "        # 设置环境变量，确保脚本可以找到项目模块\n",
        "        env = os.environ.copy()\n",
        "        env[\"PYTHONPATH\"] = project_root\n",
        "        \n",
        "        process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, env=env)\n",
        "        stdout, stderr = process.communicate()\n",
        "        \n",
        "        if process.returncode != 0:\n",
        "            print(f\"警告: 命令执行失败，返回码 {process.returncode}\")\n",
        "            print(f\"错误信息: {stderr[:500]}...\")\n",
        "            val_acc = 0\n",
        "        else:\n",
        "            val_acc = parse_output(stdout)\n",
        "            if val_acc is None:\n",
        "                val_acc = 0\n",
        "                print(\"无法解析验证准确率，使用默认值 0\")\n",
        "        \n",
        "        ablation_results.append({\n",
        "            \"ablation\": ablation,\n",
        "            \"description\": descriptions[ablation],\n",
        "            \"val_acc\": val_acc\n",
        "        })\n",
        "        print(f\"验证准确率: {val_acc:.2f}%\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"运行消融实验 {ablation} 时出错: {e}\")\n",
        "        # 添加一个包含默认值的结果\n",
        "        ablation_results.append({\n",
        "            \"ablation\": ablation,\n",
        "            \"description\": descriptions[ablation],\n",
        "            \"val_acc\": 0\n",
        "        })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "运行基准模型（无消融）...\n",
            "警告: 命令执行失败，返回码 1\n",
            "错误信息: Traceback (most recent call last):\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 197, in <module>\n",
            "    run_transformer_training() \n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 113, in run_transformer_training\n",
            "    train_loader, val_loader, vocab_size, num_classes = get_ag_news_loaders(\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 47, in get_ag_news_loaders\n",
            "    train...\n",
            "基准模型验证准确率: 0.00%\n"
          ]
        }
      ],
      "source": [
        "# 确保 project_root 已定义\n",
        "if 'project_root' not in locals():\n",
        "    project_root = os.path.abspath('..')\n",
        "    if project_root not in sys.path:\n",
        "        sys.path.insert(0, project_root)\n",
        "    os.environ[\"PYTHONPATH\"] = project_root\n",
        "\n",
        "# 先运行一次基础模型（无消融）作为对照\n",
        "print(\"运行基准模型（无消融）...\")\n",
        "try:\n",
        "    cmd = [\n",
        "        \"python\", \"../train/train_transformer.py\",\n",
        "        \"--epochs\", \"3\",\n",
        "        \"--batch-size\", \"64\",\n",
        "        \"--embed-dim\", str(embed_dim),\n",
        "        \"--num-heads\", str(num_heads),\n",
        "        \"--lr\", str(lr)\n",
        "    ]\n",
        "    # 设置环境变量，确保脚本可以找到项目模块\n",
        "    env = os.environ.copy()\n",
        "    env[\"PYTHONPATH\"] = project_root  # 使用前面定义的project_root\n",
        "    process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, env=env)\n",
        "    stdout, stderr = process.communicate()\n",
        "    \n",
        "    if process.returncode != 0:\n",
        "        print(f\"警告: 命令执行失败，返回码 {process.returncode}\")\n",
        "        print(f\"错误信息: {stderr[:500]}...\")\n",
        "        val_acc = 0\n",
        "    else:\n",
        "        val_acc = parse_output(stdout)\n",
        "        if val_acc is None:\n",
        "            val_acc = 0\n",
        "            print(\"无法解析验证准确率，使用默认值 0\")\n",
        "    \n",
        "    ablation_results.append({\n",
        "        \"ablation\": \"baseline\",\n",
        "        \"description\": \"基准模型（无消融）\",\n",
        "        \"val_acc\": val_acc\n",
        "    })\n",
        "    print(f\"基准模型验证准确率: {val_acc:.2f}%\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"运行基准模型时出错: {e}\")\n",
        "    # 添加一个包含默认值的结果，以便后续代码可以继续执行\n",
        "    ablation_results.append({\n",
        "        \"ablation\": \"baseline\",\n",
        "        \"description\": \"基准模型（无消融）\",\n",
        "        \"val_acc\": 0\n",
        "    })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "运行消融实验: no_pe - 关闭位置编码\n",
            "警告: 命令执行失败，返回码 1\n",
            "错误信息: Traceback (most recent call last):\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 197, in <module>\n",
            "    run_transformer_training() \n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 113, in run_transformer_training\n",
            "    train_loader, val_loader, vocab_size, num_classes = get_ag_news_loaders(\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 47, in get_ag_news_loaders\n",
            "    train...\n",
            "验证准确率: 0.00%\n",
            "\n",
            "运行消融实验: single_head - 只用单头注意力\n",
            "警告: 命令执行失败，返回码 1\n",
            "错误信息: Traceback (most recent call last):\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 197, in <module>\n",
            "    run_transformer_training() \n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 113, in run_transformer_training\n",
            "    train_loader, val_loader, vocab_size, num_classes = get_ag_news_loaders(\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 47, in get_ag_news_loaders\n",
            "    train...\n",
            "验证准确率: 0.00%\n",
            "\n",
            "运行消融实验: no_ffn - 移除前馈网络\n",
            "警告: 命令执行失败，返回码 1\n",
            "错误信息: Traceback (most recent call last):\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 197, in <module>\n",
            "    run_transformer_training() \n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 113, in run_transformer_training\n",
            "    train_loader, val_loader, vocab_size, num_classes = get_ag_news_loaders(\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 47, in get_ag_news_loaders\n",
            "    train...\n",
            "验证准确率: 0.00%\n",
            "\n",
            "运行消融实验: freeze_emb - 冻结embedding\n",
            "警告: 命令执行失败，返回码 1\n",
            "错误信息: Traceback (most recent call last):\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 197, in <module>\n",
            "    run_transformer_training() \n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 113, in run_transformer_training\n",
            "    train_loader, val_loader, vocab_size, num_classes = get_ag_news_loaders(\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 47, in get_ag_news_loaders\n",
            "    train...\n",
            "验证准确率: 0.00%\n",
            "\n",
            "运行消融实验: no_dropout - 关闭dropout\n",
            "警告: 命令执行失败，返回码 1\n",
            "错误信息: Traceback (most recent call last):\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 197, in <module>\n",
            "    run_transformer_training() \n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 113, in run_transformer_training\n",
            "    train_loader, val_loader, vocab_size, num_classes = get_ag_news_loaders(\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 47, in get_ag_news_loaders\n",
            "    train...\n",
            "验证准确率: 0.00%\n",
            "\n",
            "运行消融实验: clip_grad - 梯度裁剪\n",
            "警告: 命令执行失败，返回码 1\n",
            "错误信息: Traceback (most recent call last):\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 197, in <module>\n",
            "    run_transformer_training() \n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 113, in run_transformer_training\n",
            "    train_loader, val_loader, vocab_size, num_classes = get_ag_news_loaders(\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 47, in get_ag_news_loaders\n",
            "    train...\n",
            "验证准确率: 0.00%\n"
          ]
        }
      ],
      "source": [
        "# 运行各种消融实验\n",
        "descriptions = {\n",
        "    \"no_pe\": \"关闭位置编码\",\n",
        "    \"single_head\": \"只用单头注意力\",\n",
        "    \"no_ffn\": \"移除前馈网络\",\n",
        "    \"freeze_emb\": \"冻结embedding\",\n",
        "    \"no_dropout\": \"关闭dropout\",\n",
        "    \"clip_grad\": \"梯度裁剪\"\n",
        "}\n",
        "\n",
        "for ablation in ablations:\n",
        "    print(f\"\\n运行消融实验: {ablation} - {descriptions[ablation]}\")\n",
        "    try:\n",
        "        cmd = [\n",
        "            python_executable, \n",
        "            os.path.join(project_root, \"train\", \"train_transformer.py\"),\n",
        "            \"--epochs\", \"3\",\n",
        "            \"--batch-size\", \"64\",\n",
        "            \"--embed-dim\", str(embed_dim),\n",
        "            \"--num-heads\", str(num_heads),\n",
        "            \"--lr\", str(lr),\n",
        "            \"--ablation\", ablation\n",
        "        ]\n",
        "        # 设置环境变量，确保脚本可以找到项目模块\n",
        "        env = os.environ.copy()\n",
        "        env[\"PYTHONPATH\"] = project_root\n",
        "        process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, env=env)\n",
        "        stdout, stderr = process.communicate()\n",
        "        \n",
        "        if process.returncode != 0:\n",
        "            print(f\"警告: 命令执行失败，返回码 {process.returncode}\")\n",
        "            print(f\"错误信息: {stderr[:500]}...\")\n",
        "            val_acc = 0\n",
        "        else:\n",
        "            val_acc = parse_output(stdout)\n",
        "            if val_acc is None:\n",
        "                val_acc = 0\n",
        "                print(\"无法解析验证准确率，使用默认值 0\")\n",
        "        \n",
        "        ablation_results.append({\n",
        "            \"ablation\": ablation,\n",
        "            \"description\": descriptions[ablation],\n",
        "            \"val_acc\": val_acc\n",
        "        })\n",
        "        print(f\"验证准确率: {val_acc:.2f}%\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"运行消融实验 {ablation} 时出错: {e}\")\n",
        "        # 添加一个包含默认值的结果\n",
        "        ablation_results.append({\n",
        "            \"ablation\": ablation,\n",
        "            \"description\": descriptions[ablation],\n",
        "            \"val_acc\": 0\n",
        "        })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ablation</th>\n",
              "      <th>description</th>\n",
              "      <th>val_acc</th>\n",
              "      <th>rel_change</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>baseline</td>\n",
              "      <td>基准模型（无消融）</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>no_pe</td>\n",
              "      <td>关闭位置编码</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>single_head</td>\n",
              "      <td>只用单头注意力</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>no_ffn</td>\n",
              "      <td>移除前馈网络</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>freeze_emb</td>\n",
              "      <td>冻结embedding</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>no_dropout</td>\n",
              "      <td>关闭dropout</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>clip_grad</td>\n",
              "      <td>梯度裁剪</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>baseline</td>\n",
              "      <td>基准模型（无消融）</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>no_pe</td>\n",
              "      <td>关闭位置编码</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>single_head</td>\n",
              "      <td>只用单头注意力</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>no_ffn</td>\n",
              "      <td>移除前馈网络</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>freeze_emb</td>\n",
              "      <td>冻结embedding</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>no_dropout</td>\n",
              "      <td>关闭dropout</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>clip_grad</td>\n",
              "      <td>梯度裁剪</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       ablation  description  val_acc  rel_change\n",
              "0      baseline    基准模型（无消融）        0         NaN\n",
              "1         no_pe       关闭位置编码        0         NaN\n",
              "2   single_head      只用单头注意力        0         NaN\n",
              "3        no_ffn       移除前馈网络        0         NaN\n",
              "4    freeze_emb  冻结embedding        0         NaN\n",
              "5    no_dropout    关闭dropout        0         NaN\n",
              "6     clip_grad         梯度裁剪        0         NaN\n",
              "7      baseline    基准模型（无消融）        0         NaN\n",
              "8         no_pe       关闭位置编码        0         NaN\n",
              "9   single_head      只用单头注意力        0         NaN\n",
              "10       no_ffn       移除前馈网络        0         NaN\n",
              "11   freeze_emb  冻结embedding        0         NaN\n",
              "12   no_dropout    关闭dropout        0         NaN\n",
              "13    clip_grad         梯度裁剪        0         NaN"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 将消融实验结果整理为DataFrame\n",
        "ablation_df = pd.DataFrame(ablation_results)\n",
        "\n",
        "# 计算相对于基准的性能变化百分比\n",
        "# 获取基准值\n",
        "baseline_rows = ablation_df[ablation_df['ablation'] == 'baseline']\n",
        "if len(baseline_rows) > 0:\n",
        "    baseline_acc = list(baseline_rows['val_acc'])[0]\n",
        "else:\n",
        "    baseline_acc = 0\n",
        "ablation_df['rel_change'] = (ablation_df['val_acc'] - baseline_acc) / baseline_acc * 100\n",
        "\n",
        "# 排序并显示结果\n",
        "ablation_sorted = ablation_df.sort_values(by='val_acc', ascending=False)\n",
        "display(ablation_sorted)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "输出目录: c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\outputs\\transformer\n",
            "PyTorch 版本: 1.13.0+cpu\n",
            "警告: 未找到 torchtext 模块，请安装: pip install torchtext==0.14.0\n",
            "成功导入所需模块\n"
          ]
        }
      ],
      "source": [
        "# 确保环境设置正确\n",
        "import sys\n",
        "import os\n",
        "import torch\n",
        "from pathlib import Path\n",
        "\n",
        "# 设置项目路径\n",
        "project_root = os.path.abspath('..')\n",
        "if project_root not in sys.path:\n",
        "    sys.path.insert(0, project_root)\n",
        "os.environ[\"PYTHONPATH\"] = project_root\n",
        "\n",
        "# 确保输出目录存在\n",
        "output_dir = Path(project_root) / 'outputs' / 'transformer'\n",
        "output_dir.mkdir(parents=True, exist_ok=True)\n",
        "print(f\"输出目录: {output_dir}\")\n",
        "\n",
        "try:\n",
        "    # 检查依赖\n",
        "    print(f\"PyTorch 版本: {torch.__version__}\")\n",
        "    try:\n",
        "        import torchtext\n",
        "        print(f\"torchtext 版本: {torchtext.__version__}\")\n",
        "    except ImportError:\n",
        "        print(\"警告: 未找到 torchtext 模块，请安装: pip install torchtext==0.14.0\")\n",
        "    \n",
        "    # 尝试导入项目模块\n",
        "    from models.transformer import Transformer\n",
        "    from utils.text_dataloader import get_ag_news_dataloader\n",
        "    print(\"成功导入所需模块\")\n",
        "except ImportError as e:\n",
        "    print(f\"导入错误: {e}\")\n",
        "    print(\"请确保 PYTHONPATH 设置正确，并安装所需依赖: pip install torchtext==0.14.0\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:24: UserWarning: Glyph 20851 (\\N{CJK UNIFIED IDEOGRAPH-5173}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:24: UserWarning: Glyph 38381 (\\N{CJK UNIFIED IDEOGRAPH-95ED}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:24: UserWarning: Glyph 20301 (\\N{CJK UNIFIED IDEOGRAPH-4F4D}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:24: UserWarning: Glyph 32622 (\\N{CJK UNIFIED IDEOGRAPH-7F6E}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:24: UserWarning: Glyph 32534 (\\N{CJK UNIFIED IDEOGRAPH-7F16}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:24: UserWarning: Glyph 30721 (\\N{CJK UNIFIED IDEOGRAPH-7801}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:24: UserWarning: Glyph 32467 (\\N{CJK UNIFIED IDEOGRAPH-7ED3}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:24: UserWarning: Glyph 26500 (\\N{CJK UNIFIED IDEOGRAPH-6784}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:24: UserWarning: Glyph 21464 (\\N{CJK UNIFIED IDEOGRAPH-53D8}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:24: UserWarning: Glyph 20307 (\\N{CJK UNIFIED IDEOGRAPH-4F53}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:24: UserWarning: Glyph 30456 (\\N{CJK UNIFIED IDEOGRAPH-76F8}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:24: UserWarning: Glyph 23545 (\\N{CJK UNIFIED IDEOGRAPH-5BF9}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:24: UserWarning: Glyph 20934 (\\N{CJK UNIFIED IDEOGRAPH-51C6}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:24: UserWarning: Glyph 30830 (\\N{CJK UNIFIED IDEOGRAPH-786E}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:24: UserWarning: Glyph 29575 (\\N{CJK UNIFIED IDEOGRAPH-7387}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:24: UserWarning: Glyph 21270 (\\N{CJK UNIFIED IDEOGRAPH-5316}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:24: UserWarning: Glyph 21508 (\\N{CJK UNIFIED IDEOGRAPH-5404}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:24: UserWarning: Glyph 31181 (\\N{CJK UNIFIED IDEOGRAPH-79CD}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:24: UserWarning: Glyph 27169 (\\N{CJK UNIFIED IDEOGRAPH-6A21}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:24: UserWarning: Glyph 22411 (\\N{CJK UNIFIED IDEOGRAPH-578B}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:24: UserWarning: Glyph 24615 (\\N{CJK UNIFIED IDEOGRAPH-6027}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:24: UserWarning: Glyph 33021 (\\N{CJK UNIFIED IDEOGRAPH-80FD}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:24: UserWarning: Glyph 30340 (\\N{CJK UNIFIED IDEOGRAPH-7684}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:24: UserWarning: Glyph 24433 (\\N{CJK UNIFIED IDEOGRAPH-5F71}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:24: UserWarning: Glyph 21709 (\\N{CJK UNIFIED IDEOGRAPH-54CD}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:24: UserWarning: Glyph 20110 (\\N{CJK UNIFIED IDEOGRAPH-4E8E}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:24: UserWarning: Glyph 22522 (\\N{CJK UNIFIED IDEOGRAPH-57FA}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:26: UserWarning: Glyph 30456 (\\N{CJK UNIFIED IDEOGRAPH-76F8}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'ablation_results.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:26: UserWarning: Glyph 23545 (\\N{CJK UNIFIED IDEOGRAPH-5BF9}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'ablation_results.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:26: UserWarning: Glyph 20934 (\\N{CJK UNIFIED IDEOGRAPH-51C6}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'ablation_results.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:26: UserWarning: Glyph 30830 (\\N{CJK UNIFIED IDEOGRAPH-786E}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'ablation_results.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:26: UserWarning: Glyph 29575 (\\N{CJK UNIFIED IDEOGRAPH-7387}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'ablation_results.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:26: UserWarning: Glyph 21464 (\\N{CJK UNIFIED IDEOGRAPH-53D8}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'ablation_results.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:26: UserWarning: Glyph 21270 (\\N{CJK UNIFIED IDEOGRAPH-5316}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'ablation_results.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:26: UserWarning: Glyph 21508 (\\N{CJK UNIFIED IDEOGRAPH-5404}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'ablation_results.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:26: UserWarning: Glyph 31181 (\\N{CJK UNIFIED IDEOGRAPH-79CD}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'ablation_results.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:26: UserWarning: Glyph 32467 (\\N{CJK UNIFIED IDEOGRAPH-7ED3}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'ablation_results.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:26: UserWarning: Glyph 26500 (\\N{CJK UNIFIED IDEOGRAPH-6784}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'ablation_results.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:26: UserWarning: Glyph 20307 (\\N{CJK UNIFIED IDEOGRAPH-4F53}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'ablation_results.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:26: UserWarning: Glyph 27169 (\\N{CJK UNIFIED IDEOGRAPH-6A21}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'ablation_results.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:26: UserWarning: Glyph 22411 (\\N{CJK UNIFIED IDEOGRAPH-578B}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'ablation_results.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:26: UserWarning: Glyph 24615 (\\N{CJK UNIFIED IDEOGRAPH-6027}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'ablation_results.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:26: UserWarning: Glyph 33021 (\\N{CJK UNIFIED IDEOGRAPH-80FD}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'ablation_results.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:26: UserWarning: Glyph 30340 (\\N{CJK UNIFIED IDEOGRAPH-7684}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'ablation_results.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:26: UserWarning: Glyph 24433 (\\N{CJK UNIFIED IDEOGRAPH-5F71}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'ablation_results.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:26: UserWarning: Glyph 21709 (\\N{CJK UNIFIED IDEOGRAPH-54CD}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'ablation_results.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:26: UserWarning: Glyph 20110 (\\N{CJK UNIFIED IDEOGRAPH-4E8E}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'ablation_results.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:26: UserWarning: Glyph 22522 (\\N{CJK UNIFIED IDEOGRAPH-57FA}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'ablation_results.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:26: UserWarning: Glyph 20851 (\\N{CJK UNIFIED IDEOGRAPH-5173}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'ablation_results.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:26: UserWarning: Glyph 38381 (\\N{CJK UNIFIED IDEOGRAPH-95ED}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'ablation_results.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:26: UserWarning: Glyph 20301 (\\N{CJK UNIFIED IDEOGRAPH-4F4D}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'ablation_results.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:26: UserWarning: Glyph 32622 (\\N{CJK UNIFIED IDEOGRAPH-7F6E}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'ablation_results.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:26: UserWarning: Glyph 32534 (\\N{CJK UNIFIED IDEOGRAPH-7F16}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'ablation_results.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:26: UserWarning: Glyph 30721 (\\N{CJK UNIFIED IDEOGRAPH-7801}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'ablation_results.png', dpi=300, bbox_inches='tight')\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 30456 (\\N{CJK UNIFIED IDEOGRAPH-76F8}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 23545 (\\N{CJK UNIFIED IDEOGRAPH-5BF9}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 20934 (\\N{CJK UNIFIED IDEOGRAPH-51C6}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 30830 (\\N{CJK UNIFIED IDEOGRAPH-786E}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 29575 (\\N{CJK UNIFIED IDEOGRAPH-7387}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 21464 (\\N{CJK UNIFIED IDEOGRAPH-53D8}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 21270 (\\N{CJK UNIFIED IDEOGRAPH-5316}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 21508 (\\N{CJK UNIFIED IDEOGRAPH-5404}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 31181 (\\N{CJK UNIFIED IDEOGRAPH-79CD}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 32467 (\\N{CJK UNIFIED IDEOGRAPH-7ED3}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 26500 (\\N{CJK UNIFIED IDEOGRAPH-6784}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 20307 (\\N{CJK UNIFIED IDEOGRAPH-4F53}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 27169 (\\N{CJK UNIFIED IDEOGRAPH-6A21}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 22411 (\\N{CJK UNIFIED IDEOGRAPH-578B}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 24615 (\\N{CJK UNIFIED IDEOGRAPH-6027}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 33021 (\\N{CJK UNIFIED IDEOGRAPH-80FD}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 30340 (\\N{CJK UNIFIED IDEOGRAPH-7684}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 24433 (\\N{CJK UNIFIED IDEOGRAPH-5F71}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 21709 (\\N{CJK UNIFIED IDEOGRAPH-54CD}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 20110 (\\N{CJK UNIFIED IDEOGRAPH-4E8E}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 22522 (\\N{CJK UNIFIED IDEOGRAPH-57FA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 20851 (\\N{CJK UNIFIED IDEOGRAPH-5173}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 38381 (\\N{CJK UNIFIED IDEOGRAPH-95ED}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 20301 (\\N{CJK UNIFIED IDEOGRAPH-4F4D}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 32622 (\\N{CJK UNIFIED IDEOGRAPH-7F6E}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 32534 (\\N{CJK UNIFIED IDEOGRAPH-7F16}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 30721 (\\N{CJK UNIFIED IDEOGRAPH-7801}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 可视化消融实验结果\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# 不包含baseline的数据\n",
        "plot_df = ablation_df[ablation_df['ablation'] != 'baseline'].copy()\n",
        "\n",
        "# 根据相对变化排序 (这将正常工作，尽管IDE可能显示警告)\n",
        "# sort_values是pandas的标准方法，运行时不会出错\n",
        "plot_df = plot_df.sort_values('rel_change')\n",
        "\n",
        "# 创建柱状图\n",
        "bars = plt.bar(plot_df['description'], plot_df['rel_change'])\n",
        "\n",
        "# 为负值设置不同颜色\n",
        "for i, v in enumerate(plot_df['rel_change']):\n",
        "    if v < 0:\n",
        "        bars[i].set_alpha(0.7)\n",
        "\n",
        "plt.axhline(y=0, color='r', linestyle='-', alpha=0.3)\n",
        "plt.title(f\"各种结构变体对模型性能的影响 (相对于基准 {baseline_acc:.2f}%)\", fontsize=14)\n",
        "plt.xlabel(\"结构变体\")\n",
        "plt.ylabel(\"相对准确率变化 (%)\")\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.savefig(output_dir / 'ablation_results.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Attention 可视化\n",
        "\n",
        "加载最高分模型，选择一条验证集样本，可视化第1层第1个头的注意力热力图。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('..')\n",
        "import torch\n",
        "from models.transformer import Transformer\n",
        "from utils.text_dataloader import get_ag_news_dataloader\n",
        "from pathlib import Path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "需要安装 torchtext 才能使用 AG_NEWS 数据集",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[22], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 加载最佳模型\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# 获取验证数据加载器\u001b[39;00m\n\u001b[0;32m      3\u001b[0m data_dir \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m val_loader, vocab, vocab_size, num_classes \u001b[38;5;241m=\u001b[39m \u001b[43mget_ag_news_dataloader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 单条样本\u001b[39;49;00m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# 限制长度以便可视化\u001b[39;49;00m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# 根据最佳超参数创建模型\u001b[39;00m\n\u001b[0;32m     12\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\utils\\text_dataloader.py:94\u001b[0m, in \u001b[0;36mget_ag_news_dataloader\u001b[1;34m(batch_size, max_len, train, root)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;124;03m获取 AG_NEWS 数据集的 DataLoader。\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;124;03m- num_classes: 类别数量 (4 for AG_NEWS)\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m TORCHTEXT_AVAILABLE:\n\u001b[1;32m---> 94\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m需要安装 torchtext 才能使用 AG_NEWS 数据集\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     96\u001b[0m \u001b[38;5;66;03m# 确保数据目录存在\u001b[39;00m\n\u001b[0;32m     97\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(root, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[1;31mImportError\u001b[0m: 需要安装 torchtext 才能使用 AG_NEWS 数据集"
          ]
        }
      ],
      "source": [
        "# 加载最佳模型\n",
        "# 获取验证数据加载器\n",
        "data_dir = Path(\"../data\")\n",
        "val_loader, vocab, vocab_size, num_classes = get_ag_news_dataloader(\n",
        "    batch_size=1,  # 单条样本\n",
        "    max_len=128,   # 限制长度以便可视化\n",
        "    train=False,\n",
        "    root=str(data_dir)\n",
        ")\n",
        "\n",
        "# 根据最佳超参数创建模型\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = Transformer(\n",
        "    vocab_size=vocab_size,\n",
        "    embed_dim=embed_dim,\n",
        "    num_heads=num_heads,\n",
        "    hidden_dim=embed_dim*4,  # 标准Transformer通常使用4倍embed_dim作为FFN隐藏层\n",
        "    num_layers=3,\n",
        "    num_classes=num_classes\n",
        ")\n",
        "\n",
        "# 加载最佳检查点\n",
        "best_model_path = Path(\"../outputs/transformer/transformer_best.pth\")\n",
        "if best_model_path.exists():\n",
        "    model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
        "    print(f\"已加载最佳模型: {best_model_path}\")\n",
        "else:\n",
        "    print(f\"找不到最佳模型文件，使用未训练模型\")\n",
        "\n",
        "model = model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 提取单个Transformer层注意力权重的钩子函数\n",
        "class AttentionHook:\n",
        "    def __init__(self):\n",
        "        self.attn_weights = None\n",
        "        \n",
        "    def __call__(self, module, module_input, module_output):\n",
        "        # PyTorch TransformerEncoder层的attention weights在运行时不保存\n",
        "        # 我们需要修改模型结构以访问它们\n",
        "        # 这里仅为示例，实际使用时需调整\n",
        "        self.attn_weights = None  # 稍后会在前向传播中手动提取\n",
        "\n",
        "\n",
        "# 修改Transformer模型来返回注意力权重\n",
        "def forward_with_attention(model, x, src_key_padding_mask=None):\n",
        "    \"\"\"修改的前向传播，返回注意力权重\"\"\"\n",
        "    # 词嵌入 [batch_size, seq_len] -> [batch_size, seq_len, embed_dim]\n",
        "    embedded = model.embedding(x)\n",
        "    \n",
        "    # 添加位置编码\n",
        "    embedded = model.pos_encoder(embedded)\n",
        "    \n",
        "    # 我们需要访问TransformerEncoder的第一层的第一个注意力头\n",
        "    # 由于PyTorch没有直接暴露这个API，我们需要手动添加钩子或修改模型\n",
        "    # 这里是一个近似方法，实际实现可能需要更深入地修改模型\n",
        "    \n",
        "    # 使用第一个编码器层的self-attention模块\n",
        "    first_layer = model.transformer_encoder.layers[0]\n",
        "    \n",
        "    # 1. 应用自注意力，并保存注意力权重\n",
        "    # 这部分逻辑通常在TransformerEncoderLayer的内部\n",
        "    q = first_layer.self_attn.q_proj(embedded)\n",
        "    k = first_layer.self_attn.k_proj(embedded)\n",
        "    v = first_layer.self_attn.v_proj(embedded)\n",
        "    \n",
        "    # 重塑为多头形式\n",
        "    batch_size, seq_len = embedded.shape[0], embedded.shape[1]\n",
        "    head_dim = model.transformer_encoder.layers[0].self_attn.head_dim\n",
        "    num_heads = model.transformer_encoder.layers[0].self_attn.num_heads\n",
        "    \n",
        "    q = q.view(batch_size, seq_len, num_heads, head_dim).transpose(1, 2)\n",
        "    k = k.view(batch_size, seq_len, num_heads, head_dim).transpose(1, 2)\n",
        "    v = v.view(batch_size, seq_len, num_heads, head_dim).transpose(1, 2)\n",
        "    \n",
        "    # 计算注意力分数\n",
        "    scores = torch.matmul(q, k.transpose(-2, -1)) / (head_dim ** 0.5)\n",
        "    \n",
        "    # 应用掩码（如果有）\n",
        "    if src_key_padding_mask is not None:\n",
        "        # 扩展掩码以匹配分数的形状\n",
        "        mask = src_key_padding_mask.unsqueeze(1).unsqueeze(2)\n",
        "        scores = scores.masked_fill(mask, float(\"-inf\"))\n",
        "    \n",
        "    # 应用softmax得到注意力权重\n",
        "    attn_weights = torch.nn.functional.softmax(scores, dim=-1)\n",
        "    \n",
        "    # 提取第一个头的注意力权重\n",
        "    first_head_attn = attn_weights[0, 0].cpu().detach()\n",
        "    \n",
        "    # 继续常规前向传播\n",
        "    # 由于我们不需要完整的前向传播结果，这里简化了步骤\n",
        "    \n",
        "    return first_head_attn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 选择一条验证样本\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    # 获取一个批次\n",
        "    for tokens, labels, masks in val_loader:\n",
        "        tokens, labels, masks = tokens.to(device), labels.to(device), masks.to(device)\n",
        "        \n",
        "        # 使用修改后的前向传播函数获取注意力权重\n",
        "        attention_weights = forward_with_attention(model, tokens, src_key_padding_mask=masks)\n",
        "        \n",
        "        # 获取真实标记（而不是填充标记）\n",
        "        valid_seq_len = (~masks[0]).sum().item()\n",
        "        \n",
        "        # 可视化注意力热力图\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        \n",
        "        # 只显示有效的标记（不显示填充标记）\n",
        "        valid_attn = attention_weights[:valid_seq_len, :valid_seq_len]\n",
        "        \n",
        "        # 创建热力图\n",
        "        sns.heatmap(valid_attn, cmap=\"viridis\")\n",
        "        plt.title(f\"第1层第1个头的Self-Attention热力图 (类别: {labels.item()+1})\")\n",
        "        plt.xlabel(\"Token位置\")\n",
        "        plt.ylabel(\"Token位置\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(output_dir / 'attention_heatmap.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "        \n",
        "        # 一条样本就够了\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 结论总结\n",
        "\n",
        "1. **超参数实验结论**\n",
        "   - 最佳超参数组合及其性能表现\n",
        "   - embedding维度与head数量的关系\n",
        "   - 学习率对不同模型规模的影响\n",
        "\n",
        "2. **结构变体实验结论**\n",
        "   - 各组件对模型性能的影响排序\n",
        "   - 哪些组件是必不可少的，哪些影响较小\n",
        "\n",
        "3. **注意力可视化分析**\n",
        "   - 模型关注了哪些位置的token\n",
        "   - 是否存在明显的注意力模式\n",
        "\n",
        "4. **TODO 与改进方向**\n",
        "   - 尝试更多超参数组合\n",
        "   - 增加序列长度或批量大小\n",
        "   - 尝试不同的位置编码方案\n",
        "   - 探索预训练与微调策略\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "dl",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
