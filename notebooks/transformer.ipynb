{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 使用说明\n",
        "\n",
        "# 如果你遇到\"cannot import name 'PROJECT_ROOT' from 'utils'\"错误，请按以下步骤操作：\n",
        "# \n",
        "# 1. 按顺序运行以下单元格：\n",
        "#    - 第一个单元格 - 配置项目路径\n",
        "#    - 第二个单元格 - 修复PROJECT_ROOT导入问题\n",
        "#    - 第三个单元格 - 诊断导入问题\n",
        "#    - 第四个单元格 - 安装兼容依赖（如果需要）\n",
        "# \n",
        "# 2. 修复后请重启Jupyter内核：\n",
        "#    - Kernel -> Restart Kernel\n",
        "# \n",
        "# 3. 重启后再次按顺序运行单元格\n",
        "# \n",
        "# 如果仍有问题，可能的解决方案：\n",
        "# - 确认PyTorch、torchtext和torchvision版本兼容\n",
        "# - 检查train_transformer.py中的导入方式\n",
        "# - 确保utils/__init__.py中正确导出了PROJECT_ROOT\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Transformer 实验与调参手册 (AG NEWS)\n",
        "\n",
        "## 目录\n",
        "- [环境准备](#环境准备)\n",
        "- [单次 Baseline 训练](#单次-Baseline-训练)\n",
        "- [超参数网格搜索](#超参数网格搜索)\n",
        "- [结果汇总表](#结果汇总表)\n",
        "- [曲线可视化](#曲线可视化)\n",
        "- [拆零件小实验](#拆零件小实验)\n",
        "- [Attention 可视化](#Attention-可视化)\n",
        "- [结论总结](#结论总结)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 环境准备\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "项目根目录: c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\n",
            "输出目录: c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\outputs\\transformer\n",
            "数据目录: c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\data\n",
            "PyTorch 版本: 2.5.1\n",
            "CUDA 可用: False\n",
            "torchtext 版本: 0.6.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_11396\\202672887.py:38: UserWarning: torchtext版本(0.6.0)与推荐版本(0.14.0)不一致\n",
            "  warnings.warn(f\"{module_name}版本({module.__version__})与推荐版本({required_version})不一致\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torchvision 版本: 0.20.1\n",
            "已成功导入 torchtext，版本: 0.6.0\n",
            "✓ 所有项目模块导入成功\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_11396\\202672887.py:38: UserWarning: torchvision版本(0.20.1)与推荐版本(0.14.0)不一致\n",
            "  warnings.warn(f\"{module_name}版本({module.__version__})与推荐版本({required_version})不一致\")\n"
          ]
        }
      ],
      "source": [
        "# 环境检查与配置\n",
        "import os, sys\n",
        "from pathlib import Path\n",
        "import importlib\n",
        "import torch\n",
        "import warnings\n",
        "\n",
        "# 设置项目根目录路径\n",
        "project_root = os.path.abspath('..')\n",
        "if project_root not in sys.path:\n",
        "    sys.path.insert(0, project_root)\n",
        "os.environ[\"PYTHONPATH\"] = project_root\n",
        "\n",
        "# 创建必要的目录\n",
        "output_dir = Path(project_root) / 'outputs' / 'transformer'\n",
        "output_dir.mkdir(parents=True, exist_ok=True)\n",
        "data_dir = Path(project_root) / 'data'\n",
        "data_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 检查关键模块与版本\n",
        "print(f\"项目根目录: {project_root}\")\n",
        "print(f\"输出目录: {output_dir}\")\n",
        "print(f\"数据目录: {data_dir}\")\n",
        "print(f\"PyTorch 版本: {torch.__version__}\")\n",
        "print(f\"CUDA 可用: {torch.cuda.is_available()}\")\n",
        "\n",
        "# 检查必要的依赖\n",
        "dependencies = {\n",
        "    'torchtext': '0.14.0',\n",
        "    'torchvision': '0.14.0'\n",
        "}\n",
        "\n",
        "for module_name, required_version in dependencies.items():\n",
        "    try:\n",
        "        module = importlib.import_module(module_name)\n",
        "        print(f\"{module_name} 版本: {module.__version__}\")\n",
        "        if module.__version__ != required_version:\n",
        "            warnings.warn(f\"{module_name}版本({module.__version__})与推荐版本({required_version})不一致\")\n",
        "    except ImportError:\n",
        "        print(f\"未安装{module_name}，请运行: pip install {module_name}=={required_version}\")\n",
        "\n",
        "# 检查项目模块导入\n",
        "try:\n",
        "    from utils import text_dataloader, dataloader\n",
        "    from train import train_transformer\n",
        "    from models import transformer\n",
        "    print(\"✓ 所有项目模块导入成功\")\n",
        "except Exception as e:\n",
        "    print(f\"项目模块导入错误: {e}\")\n",
        "    print(\"请确保utils/__init__.py正确配置了PROJECT_ROOT\")\n",
        "\n",
        "# Jupyter notebook相关配置\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 导入必要模块\n",
        "import torch\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import subprocess\n",
        "import json\n",
        "import sys\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch版本: 2.5.1\n",
            "torchtext版本: 0.6.0\n",
            "torchvision版本: 0.20.1\n",
            "seaborn已安装\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_11396\\3406789192.py:41: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
            "  import pkg_resources\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "seaborn版本: 0.13.2\n",
            "\n",
            "⚠️ 检测到以下兼容性问题:\n",
            "- PyTorch版本建议使用1.x.x系列，当前为2.5.1\n",
            "- torchtext版本(0.6.0)与PyTorch版本(2.5.1)不兼容\n",
            "\n",
            "建议修复方案:\n",
            "- 针对PyTorch 1.13.x: pip install torchtext==0.14.0\n",
            "- 针对PyTorch 2.x: pip install torchtext>=0.15.0\n",
            "- 如遇内存溢出: 运行根目录下的clear_cache.py脚本\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 添加兼容性检查工具，用于确认环境兼容性并提供修复建议\n",
        "\n",
        "def check_compatibility():\n",
        "    \"\"\"检查环境兼容性并提供修复建议\"\"\"\n",
        "    compatibility_issues = []\n",
        "    \n",
        "    # 检查PyTorch版本\n",
        "    try:\n",
        "        import torch\n",
        "        print(f\"PyTorch版本: {torch.__version__}\")\n",
        "        if torch.__version__.split('.')[0] != '1':\n",
        "            compatibility_issues.append(f\"PyTorch版本建议使用1.x.x系列，当前为{torch.__version__}\")\n",
        "    except ImportError:\n",
        "        compatibility_issues.append(\"未安装PyTorch\")\n",
        "    \n",
        "    # 检查torchtext\n",
        "    try:\n",
        "        import torchtext\n",
        "        print(f\"torchtext版本: {torchtext.__version__}\")\n",
        "        \n",
        "        # 检查与PyTorch版本的兼容性\n",
        "        if torch.__version__.split('.')[0] != torchtext.__version__.split('.')[0]:\n",
        "            compatibility_issues.append(f\"torchtext版本({torchtext.__version__})与PyTorch版本({torch.__version__})不兼容\")\n",
        "            \n",
        "    except ImportError:\n",
        "        compatibility_issues.append(\"未安装torchtext，请运行: pip install torchtext==0.14.0\")\n",
        "    \n",
        "    # 检查torchvision\n",
        "    try:\n",
        "        import torchvision\n",
        "        print(f\"torchvision版本: {torchvision.__version__}\")\n",
        "    except ImportError:\n",
        "        compatibility_issues.append(\"未安装torchvision\")\n",
        "    \n",
        "    # 检查seaborn (用于可视化)\n",
        "    try:\n",
        "        import seaborn\n",
        "        print(f\"seaborn已安装\")\n",
        "        # 尝试获取版本信息而不使用__version__\n",
        "        try:\n",
        "            import pkg_resources\n",
        "            seaborn_version = pkg_resources.get_distribution(\"seaborn\").version\n",
        "            print(f\"seaborn版本: {seaborn_version}\")\n",
        "        except:\n",
        "            print(\"无法获取seaborn版本\")\n",
        "    except ImportError:\n",
        "        compatibility_issues.append(\"未安装seaborn，可视化功能可能受限\")\n",
        "    \n",
        "    # 显示总结\n",
        "    if compatibility_issues:\n",
        "        print(\"\\n⚠️ 检测到以下兼容性问题:\")\n",
        "        for issue in compatibility_issues:\n",
        "            print(f\"- {issue}\")\n",
        "        \n",
        "        print(\"\\n建议修复方案:\")\n",
        "        print(\"- 针对PyTorch 1.13.x: pip install torchtext==0.14.0\")\n",
        "        print(\"- 针对PyTorch 2.x: pip install torchtext>=0.15.0\")\n",
        "        print(\"- 如遇内存溢出: 运行根目录下的clear_cache.py脚本\")\n",
        "        return False\n",
        "    else:\n",
        "        print(\"\\n✅ 环境兼容性检查通过！\")\n",
        "        return True\n",
        "\n",
        "# 运行兼容性检查\n",
        "check_compatibility()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 单次 Baseline 训练\n",
        "\n",
        "首先运行一次基础训练，确保代码无错误且能成功训练。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "运行训练脚本...\n",
            "PYTHONPATH: c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\n",
            "使用Python解释器: c:\\Users\\WHY\\anaconda3\\envs\\dl\\python.exe\n",
            "训练脚本: c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\n",
            "执行命令: c:\\Users\\WHY\\anaconda3\\envs\\dl\\python.exe c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py --epochs 5 --batch-size 64 --lr 1e-3 --embed-dim 128 --output-dir c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\outputs\\transformer\n"
          ]
        }
      ],
      "source": [
        "# 运行基础训练\n",
        "import subprocess\n",
        "\n",
        "print(\"运行训练脚本...\")\n",
        "print(f\"PYTHONPATH: {os.environ.get('PYTHONPATH')}\")\n",
        "\n",
        "# 使用当前的Python解释器\n",
        "python_executable = sys.executable\n",
        "print(f\"使用Python解释器: {python_executable}\")\n",
        "\n",
        "# 确保train_transformer.py文件存在\n",
        "train_script = os.path.join(project_root, \"train\", \"train_transformer.py\")\n",
        "if not os.path.exists(train_script):\n",
        "    raise FileNotFoundError(f\"训练脚本不存在: {train_script}\")\n",
        "print(f\"训练脚本: {train_script}\")\n",
        "\n",
        "# 构建命令\n",
        "cmd = [\n",
        "    python_executable, \n",
        "    train_script,\n",
        "    \"--epochs\", \"5\",\n",
        "    \"--batch-size\", \"64\",\n",
        "    \"--lr\", \"1e-3\",\n",
        "    \"--embed-dim\", \"128\",\n",
        "    \"--output-dir\", str(output_dir)\n",
        "]\n",
        "\n",
        "# 运行命令\n",
        "print(f\"执行命令: {' '.join(cmd)}\")\n",
        "env = os.environ.copy()\n",
        "result = subprocess.run(\n",
        "    cmd, \n",
        "    env=env, \n",
        "    stdout=subprocess.PIPE, \n",
        "    stderr=subprocess.PIPE,\n",
        "    text=True\n",
        ")\n",
        "\n",
        "# 输出结果\n",
        "if result.returncode != 0:\n",
        "    print(f\"命令执行失败，错误码: {result.returncode}\")\n",
        "    print(f\"错误输出:\")\n",
        "    print(result.stderr)\n",
        "else:\n",
        "    print(\"训练完成！\")\n",
        "    print(result.stdout)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 超参数网格搜索\n",
        "\n",
        "定义一组系统化的超参数组合，进行网格搜索实验。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 定义超参数网格\n",
        "grid = [\n",
        "    {\"embed_dim\": d, \"num_heads\": h, \"lr\": lr}\n",
        "    for d, h in [(64, 2), (128, 4), (256, 8)]\n",
        "    for lr in [5e-4, 1e-3]\n",
        "]\n",
        "results = []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 函数用于解析输出中的验证准确率\n",
        "def parse_output(output_str):\n",
        "    lines = output_str.split('\\n')\n",
        "    val_acc = None\n",
        "    for line in lines:\n",
        "        if \"Val loss\" in line:\n",
        "            parts = line.split(',')\n",
        "            if len(parts) > 1:\n",
        "                acc_part = parts[1].strip()\n",
        "                val_acc = float(acc_part.replace('Acc: ', '').replace('%', ''))\n",
        "    return val_acc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "输出目录: c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\outputs\\transformer\n",
            "数据目录: c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\data\n",
            "使用 Python 解释器: c:\\Users\\WHY\\anaconda3\\envs\\dl\\python.exe\n",
            "训练脚本: c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\n",
            "\n",
            "实验 1/6: {'embed_dim': 64, 'num_heads': 2, 'lr': 0.0005}\n",
            "执行命令: c:\\Users\\WHY\\anaconda3\\envs\\dl\\python.exe c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py --epochs 3 --batch-size 64 --embed-dim 64 --num-heads 2 --lr 0.0005 --output-dir c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\outputs\\transformer\\exp_64_2_0.0005\n",
            "警告: 命令执行失败，返回码 1\n",
            "错误信息: Traceback (most recent call last):\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 197, in <module>\n",
            "    run_transformer_training() \n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 113, in run_transformer_training\n",
            "    train_loader, val_loader, vocab_size, num_classes = get_ag_news_loaders(\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 47, in get_ag_news_loaders\n",
            "    train...\n",
            "无法获取验证准确率\n",
            "\n",
            "实验 2/6: {'embed_dim': 64, 'num_heads': 2, 'lr': 0.001}\n",
            "执行命令: c:\\Users\\WHY\\anaconda3\\envs\\dl\\python.exe c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py --epochs 3 --batch-size 64 --embed-dim 64 --num-heads 2 --lr 0.001 --output-dir c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\outputs\\transformer\\exp_64_2_0.001\n",
            "警告: 命令执行失败，返回码 1\n",
            "错误信息: Traceback (most recent call last):\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 197, in <module>\n",
            "    run_transformer_training() \n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 113, in run_transformer_training\n",
            "    train_loader, val_loader, vocab_size, num_classes = get_ag_news_loaders(\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 47, in get_ag_news_loaders\n",
            "    train...\n",
            "无法获取验证准确率\n",
            "\n",
            "实验 3/6: {'embed_dim': 128, 'num_heads': 4, 'lr': 0.0005}\n",
            "执行命令: c:\\Users\\WHY\\anaconda3\\envs\\dl\\python.exe c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py --epochs 3 --batch-size 64 --embed-dim 128 --num-heads 4 --lr 0.0005 --output-dir c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\outputs\\transformer\\exp_128_4_0.0005\n",
            "警告: 命令执行失败，返回码 1\n",
            "错误信息: Traceback (most recent call last):\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 197, in <module>\n",
            "    run_transformer_training() \n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 113, in run_transformer_training\n",
            "    train_loader, val_loader, vocab_size, num_classes = get_ag_news_loaders(\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 47, in get_ag_news_loaders\n",
            "    train...\n",
            "无法获取验证准确率\n",
            "\n",
            "实验 4/6: {'embed_dim': 128, 'num_heads': 4, 'lr': 0.001}\n",
            "执行命令: c:\\Users\\WHY\\anaconda3\\envs\\dl\\python.exe c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py --epochs 3 --batch-size 64 --embed-dim 128 --num-heads 4 --lr 0.001 --output-dir c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\outputs\\transformer\\exp_128_4_0.001\n",
            "警告: 命令执行失败，返回码 1\n",
            "错误信息: Traceback (most recent call last):\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 197, in <module>\n",
            "    run_transformer_training() \n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 113, in run_transformer_training\n",
            "    train_loader, val_loader, vocab_size, num_classes = get_ag_news_loaders(\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 47, in get_ag_news_loaders\n",
            "    train...\n",
            "无法获取验证准确率\n",
            "\n",
            "实验 5/6: {'embed_dim': 256, 'num_heads': 8, 'lr': 0.0005}\n",
            "执行命令: c:\\Users\\WHY\\anaconda3\\envs\\dl\\python.exe c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py --epochs 3 --batch-size 64 --embed-dim 256 --num-heads 8 --lr 0.0005 --output-dir c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\outputs\\transformer\\exp_256_8_0.0005\n",
            "警告: 命令执行失败，返回码 1\n",
            "错误信息: Traceback (most recent call last):\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 197, in <module>\n",
            "    run_transformer_training() \n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 113, in run_transformer_training\n",
            "    train_loader, val_loader, vocab_size, num_classes = get_ag_news_loaders(\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 47, in get_ag_news_loaders\n",
            "    train...\n",
            "无法获取验证准确率\n",
            "\n",
            "实验 6/6: {'embed_dim': 256, 'num_heads': 8, 'lr': 0.001}\n",
            "执行命令: c:\\Users\\WHY\\anaconda3\\envs\\dl\\python.exe c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py --epochs 3 --batch-size 64 --embed-dim 256 --num-heads 8 --lr 0.001 --output-dir c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\outputs\\transformer\\exp_256_8_0.001\n",
            "警告: 命令执行失败，返回码 1\n",
            "错误信息: Traceback (most recent call last):\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 197, in <module>\n",
            "    run_transformer_training() \n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 113, in run_transformer_training\n",
            "    train_loader, val_loader, vocab_size, num_classes = get_ag_news_loaders(\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 47, in get_ag_news_loaders\n",
            "    train...\n",
            "无法获取验证准确率\n"
          ]
        }
      ],
      "source": [
        "# 确保 PYTHONPATH 和 sys.path 正确设置\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import time\n",
        "\n",
        "project_root = os.path.abspath('..')\n",
        "if project_root not in sys.path:\n",
        "    sys.path.insert(0, project_root)\n",
        "os.environ[\"PYTHONPATH\"] = project_root\n",
        "\n",
        "# 确保输出目录存在\n",
        "output_dir = Path(project_root) / 'outputs' / 'transformer'\n",
        "output_dir.mkdir(parents=True, exist_ok=True)\n",
        "print(f\"输出目录: {output_dir}\")\n",
        "\n",
        "# 确保数据目录存在\n",
        "data_dir = Path(project_root) / 'data'\n",
        "data_dir.mkdir(parents=True, exist_ok=True)\n",
        "print(f\"数据目录: {data_dir}\")\n",
        "\n",
        "# 获取当前 Python 解释器路径\n",
        "python_executable = sys.executable\n",
        "print(f\"使用 Python 解释器: {python_executable}\")\n",
        "\n",
        "# 确保训练脚本存在\n",
        "train_script = os.path.join(project_root, \"train\", \"train_transformer.py\")\n",
        "if not os.path.exists(train_script):\n",
        "    raise FileNotFoundError(f\"训练脚本不存在: {train_script}\")\n",
        "print(f\"训练脚本: {train_script}\")\n",
        "\n",
        "# 循环执行每个超参数组合的实验\n",
        "for i, params in enumerate(grid):\n",
        "    print(f\"\\n实验 {i+1}/{len(grid)}: {params}\")\n",
        "    \n",
        "    try:\n",
        "        # 为每个实验创建唯一的输出目录\n",
        "        exp_dir = output_dir / f\"exp_{params['embed_dim']}_{params['num_heads']}_{params['lr']}\"\n",
        "        exp_dir.mkdir(parents=True, exist_ok=True)\n",
        "        \n",
        "        # 构建命令\n",
        "        cmd = [\n",
        "            python_executable, \n",
        "            train_script,\n",
        "            \"--epochs\", \"3\",\n",
        "            \"--batch-size\", \"64\",\n",
        "            \"--embed-dim\", str(params['embed_dim']),\n",
        "            \"--num-heads\", str(params['num_heads']),\n",
        "            \"--lr\", str(params['lr']),\n",
        "            \"--output-dir\", str(exp_dir)\n",
        "        ]\n",
        "        \n",
        "        # 设置环境变量，确保脚本可以找到项目模块\n",
        "        env = os.environ.copy()\n",
        "        env[\"PYTHONPATH\"] = project_root\n",
        "        \n",
        "        # 执行命令并捕获输出\n",
        "        print(f\"执行命令: {' '.join(cmd)}\")\n",
        "        process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, env=env)\n",
        "        stdout, stderr = process.communicate()\n",
        "        \n",
        "        if process.returncode != 0:\n",
        "            print(f\"警告: 命令执行失败，返回码 {process.returncode}\")\n",
        "            print(f\"错误信息: {stderr[:500]}...\")\n",
        "            val_acc = None\n",
        "        else:\n",
        "            # 解析验证准确率\n",
        "            val_acc = parse_output(stdout)\n",
        "            \n",
        "        # 将结果添加到列表\n",
        "        result = params.copy()\n",
        "        result['val_acc'] = val_acc\n",
        "        results.append(result)\n",
        "        \n",
        "        if val_acc is not None:\n",
        "            print(f\"验证准确率: {val_acc:.2f}%\")\n",
        "        else:\n",
        "            print(\"无法获取验证准确率\")\n",
        "            \n",
        "        # 保存当前结果（即使有错误也保存部分结果）\n",
        "        results_df = pd.DataFrame(results)\n",
        "        results_df.to_csv(output_dir / \"grid_search_results.csv\", index=False)\n",
        "        \n",
        "        # 短暂暂停，避免系统资源过度使用\n",
        "        time.sleep(1)\n",
        "    \n",
        "    except Exception as e:\n",
        "        print(f\"实验执行出错: {e}\")\n",
        "        # 添加一个包含错误信息的结果\n",
        "        results.append({\n",
        "            **params,\n",
        "            'val_acc': None,\n",
        "            'error': str(e)\n",
        "        })\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 结果汇总表\n",
        "\n",
        "将网格搜索结果整理成 DataFrame 并排序。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>embed_dim</th>\n",
              "      <th>num_heads</th>\n",
              "      <th>lr</th>\n",
              "      <th>val_acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>64</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>64</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>128</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>128</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>256</td>\n",
              "      <td>8</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>256</td>\n",
              "      <td>8</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   embed_dim  num_heads      lr val_acc\n",
              "0         64          2  0.0005    None\n",
              "1         64          2  0.0010    None\n",
              "2        128          4  0.0005    None\n",
              "3        128          4  0.0010    None\n",
              "4        256          8  0.0005    None\n",
              "5        256          8  0.0010    None"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 转换为 DataFrame\n",
        "df = pd.DataFrame(results)\n",
        "\n",
        "# 按验证准确率降序排序\n",
        "df_sorted = df.sort_values(by='val_acc', ascending=False)\n",
        "display(df_sorted)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 曲线可视化\n",
        "\n",
        "绘制超参数对性能影响的曲线图。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "可视化输出目录: c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\outputs\\transformer\\viz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\1176968519.py:29: UserWarning: Glyph 25968 (\\N{CJK UNIFIED IDEOGRAPH-6570}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\1176968519.py:29: UserWarning: Glyph 25454 (\\N{CJK UNIFIED IDEOGRAPH-636E}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\1176968519.py:29: UserWarning: Glyph 32570 (\\N{CJK UNIFIED IDEOGRAPH-7F3A}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\1176968519.py:29: UserWarning: Glyph 22833 (\\N{CJK UNIFIED IDEOGRAPH-5931}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\1176968519.py:29: UserWarning: Glyph 65292 (\\N{FULLWIDTH COMMA}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\1176968519.py:29: UserWarning: Glyph 26080 (\\N{CJK UNIFIED IDEOGRAPH-65E0}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\1176968519.py:29: UserWarning: Glyph 27861 (\\N{CJK UNIFIED IDEOGRAPH-6CD5}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\1176968519.py:29: UserWarning: Glyph 29983 (\\N{CJK UNIFIED IDEOGRAPH-751F}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\1176968519.py:29: UserWarning: Glyph 25104 (\\N{CJK UNIFIED IDEOGRAPH-6210}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\1176968519.py:29: UserWarning: Glyph 22270 (\\N{CJK UNIFIED IDEOGRAPH-56FE}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\1176968519.py:29: UserWarning: Glyph 34920 (\\N{CJK UNIFIED IDEOGRAPH-8868}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\1176968519.py:29: UserWarning: Glyph 27809 (\\N{CJK UNIFIED IDEOGRAPH-6CA1}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\1176968519.py:29: UserWarning: Glyph 26377 (\\N{CJK UNIFIED IDEOGRAPH-6709}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\1176968519.py:29: UserWarning: Glyph 25928 (\\N{CJK UNIFIED IDEOGRAPH-6548}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\1176968519.py:29: UserWarning: Glyph 30340 (\\N{CJK UNIFIED IDEOGRAPH-7684}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\1176968519.py:29: UserWarning: Glyph 23454 (\\N{CJK UNIFIED IDEOGRAPH-5B9E}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\1176968519.py:29: UserWarning: Glyph 39564 (\\N{CJK UNIFIED IDEOGRAPH-9A8C}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_file, dpi=300, bbox_inches='tight')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "图像已保存: c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\outputs\\transformer\\viz\\param_impact.png\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 25968 (\\N{CJK UNIFIED IDEOGRAPH-6570}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 25454 (\\N{CJK UNIFIED IDEOGRAPH-636E}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 32570 (\\N{CJK UNIFIED IDEOGRAPH-7F3A}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 22833 (\\N{CJK UNIFIED IDEOGRAPH-5931}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 65292 (\\N{FULLWIDTH COMMA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 26080 (\\N{CJK UNIFIED IDEOGRAPH-65E0}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 27861 (\\N{CJK UNIFIED IDEOGRAPH-6CD5}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 29983 (\\N{CJK UNIFIED IDEOGRAPH-751F}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 25104 (\\N{CJK UNIFIED IDEOGRAPH-6210}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 22270 (\\N{CJK UNIFIED IDEOGRAPH-56FE}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 34920 (\\N{CJK UNIFIED IDEOGRAPH-8868}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 27809 (\\N{CJK UNIFIED IDEOGRAPH-6CA1}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 26377 (\\N{CJK UNIFIED IDEOGRAPH-6709}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 25928 (\\N{CJK UNIFIED IDEOGRAPH-6548}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 30340 (\\N{CJK UNIFIED IDEOGRAPH-7684}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 23454 (\\N{CJK UNIFIED IDEOGRAPH-5B9E}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 39564 (\\N{CJK UNIFIED IDEOGRAPH-9A8C}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 确保输出目录存在\n",
        "from pathlib import Path\n",
        "output_dir = Path(project_root) / 'outputs' / 'transformer'\n",
        "output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 确保可视化目录存在\n",
        "viz_dir = output_dir / 'viz'\n",
        "viz_dir.mkdir(parents=True, exist_ok=True)\n",
        "print(f\"可视化输出目录: {viz_dir}\")\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# 检查数据是否存在有效值\n",
        "if len(df[df[\"val_acc\"].notnull()]) == 0:\n",
        "    plt.text(0.5, 0.5, \"没有有效的实验数据\", \n",
        "             horizontalalignment='center', verticalalignment='center',\n",
        "             fontsize=18, transform=plt.gca().transAxes)\n",
        "    plt.title(\"数据缺失，无法生成图表\")\n",
        "else:\n",
        "    # 1. Embedding维度对准确率影响\n",
        "    sns.lineplot(data=df, x=\"embed_dim\", y=\"val_acc\", hue=\"num_heads\", style=\"lr\")\n",
        "    plt.title(\"Embedding 维度 / Head 数 / LR 对准确率影响\")\n",
        "    plt.xlabel(\"Embedding 维度\")\n",
        "    plt.ylabel(\"验证准确率 (%)\")\n",
        "    plt.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "# 保存图像\n",
        "output_file = viz_dir / 'param_impact.png'\n",
        "plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
        "print(f\"图像已保存: {output_file}\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\2780070185.py:9: UserWarning: Glyph 39564 (\\N{CJK UNIFIED IDEOGRAPH-9A8C}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'lr_impact.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\2780070185.py:9: UserWarning: Glyph 35777 (\\N{CJK UNIFIED IDEOGRAPH-8BC1}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'lr_impact.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\2780070185.py:9: UserWarning: Glyph 20934 (\\N{CJK UNIFIED IDEOGRAPH-51C6}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'lr_impact.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\2780070185.py:9: UserWarning: Glyph 30830 (\\N{CJK UNIFIED IDEOGRAPH-786E}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'lr_impact.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\2780070185.py:9: UserWarning: Glyph 29575 (\\N{CJK UNIFIED IDEOGRAPH-7387}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'lr_impact.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\2780070185.py:9: UserWarning: Glyph 32500 (\\N{CJK UNIFIED IDEOGRAPH-7EF4}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'lr_impact.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\2780070185.py:9: UserWarning: Glyph 24230 (\\N{CJK UNIFIED IDEOGRAPH-5EA6}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'lr_impact.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\2780070185.py:9: UserWarning: Glyph 23398 (\\N{CJK UNIFIED IDEOGRAPH-5B66}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'lr_impact.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\2780070185.py:9: UserWarning: Glyph 20064 (\\N{CJK UNIFIED IDEOGRAPH-4E60}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'lr_impact.png', dpi=300, bbox_inches='tight')\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 39564 (\\N{CJK UNIFIED IDEOGRAPH-9A8C}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 35777 (\\N{CJK UNIFIED IDEOGRAPH-8BC1}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 20934 (\\N{CJK UNIFIED IDEOGRAPH-51C6}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 30830 (\\N{CJK UNIFIED IDEOGRAPH-786E}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 29575 (\\N{CJK UNIFIED IDEOGRAPH-7387}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 32500 (\\N{CJK UNIFIED IDEOGRAPH-7EF4}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 24230 (\\N{CJK UNIFIED IDEOGRAPH-5EA6}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 23398 (\\N{CJK UNIFIED IDEOGRAPH-5B66}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 20064 (\\N{CJK UNIFIED IDEOGRAPH-4E60}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1290.99x500 with 3 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 2. 学习率对不同模型规模的影响\n",
        "g = sns.catplot(\n",
        "    data=df, x=\"lr\", y=\"val_acc\", \n",
        "    col=\"embed_dim\", hue=\"num_heads\",\n",
        "    kind=\"bar\", height=5, aspect=0.8\n",
        ")\n",
        "g.set_axis_labels(\"学习率\", \"验证准确率 (%)\")\n",
        "g.set_titles(\"Embedding维度: {col_name}\")\n",
        "plt.savefig(output_dir / 'lr_impact.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 拆零件小实验\n",
        "\n",
        "进行6种结构变体实验，观察各组件对模型性能的影响。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 定义消融实验列表\n",
        "ablations = [\n",
        "    \"no_pe\",        # 关闭位置编码\n",
        "    \"single_head\",  # 只用单头注意力\n",
        "    \"no_ffn\",       # 移除前馈网络\n",
        "    \"freeze_emb\",   # 冻结embedding\n",
        "    \"no_dropout\",   # 关闭dropout\n",
        "    \"clip_grad\"     # 梯度裁剪\n",
        "]\n",
        "\n",
        "# 获取最佳配置作为基准\n",
        "best_config = df_sorted.iloc[0].to_dict()\n",
        "embed_dim = int(best_config['embed_dim'])\n",
        "num_heads = int(best_config['num_heads'])\n",
        "lr = best_config['lr']\n",
        "\n",
        "ablation_results = []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "使用 Python 解释器: c:\\Users\\WHY\\anaconda3\\envs\\dl\\python.exe\n",
            "运行基准模型（无消融）...\n",
            "警告: 命令执行失败，返回码 1\n",
            "错误信息: Traceback (most recent call last):\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 197, in <module>\n",
            "    run_transformer_training() \n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 113, in run_transformer_training\n",
            "    train_loader, val_loader, vocab_size, num_classes = get_ag_news_loaders(\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 47, in get_ag_news_loaders\n",
            "    train...\n",
            "基准模型验证准确率: 0.00%\n"
          ]
        }
      ],
      "source": [
        "# 确保 project_root 已定义\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "if 'project_root' not in locals():\n",
        "    project_root = os.path.abspath('..')\n",
        "    if project_root not in sys.path:\n",
        "        sys.path.insert(0, project_root)\n",
        "    os.environ[\"PYTHONPATH\"] = project_root\n",
        "\n",
        "# 确保输出目录存在\n",
        "output_dir = Path(project_root) / 'outputs' / 'transformer'\n",
        "output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 获取 Python 解释器路径\n",
        "python_executable = sys.executable\n",
        "print(f\"使用 Python 解释器: {python_executable}\")\n",
        "\n",
        "# 先运行一次基础模型（无消融）作为对照\n",
        "print(\"运行基准模型（无消融）...\")\n",
        "try:\n",
        "    cmd = [\n",
        "        python_executable, \n",
        "        os.path.join(project_root, \"train\", \"train_transformer.py\"),\n",
        "        \"--epochs\", \"3\",\n",
        "        \"--batch-size\", \"64\",\n",
        "        \"--embed-dim\", str(embed_dim),\n",
        "        \"--num-heads\", str(num_heads),\n",
        "        \"--lr\", str(lr)\n",
        "    ]\n",
        "    # 设置环境变量，确保脚本可以找到项目模块\n",
        "    env = os.environ.copy()\n",
        "    env[\"PYTHONPATH\"] = project_root\n",
        "    \n",
        "    process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, env=env)\n",
        "    stdout, stderr = process.communicate()\n",
        "    \n",
        "    if process.returncode != 0:\n",
        "        print(f\"警告: 命令执行失败，返回码 {process.returncode}\")\n",
        "        print(f\"错误信息: {stderr[:500]}...\")\n",
        "        val_acc = 0\n",
        "    else:\n",
        "        val_acc = parse_output(stdout)\n",
        "        if val_acc is None:\n",
        "            val_acc = 0\n",
        "            print(\"无法解析验证准确率，使用默认值 0\")\n",
        "    \n",
        "    ablation_results.append({\n",
        "        \"ablation\": \"baseline\",\n",
        "        \"description\": \"基准模型（无消融）\",\n",
        "        \"val_acc\": val_acc\n",
        "    })\n",
        "    print(f\"基准模型验证准确率: {val_acc:.2f}%\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"运行基准模型时出错: {e}\")\n",
        "    # 添加一个包含默认值的结果，以便后续代码可以继续执行\n",
        "    ablation_results.append({\n",
        "        \"ablation\": \"baseline\",\n",
        "        \"description\": \"基准模型（无消融）\",\n",
        "        \"val_acc\": 0\n",
        "    })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "运行消融实验: no_pe - 关闭位置编码\n",
            "警告: 命令执行失败，返回码 1\n",
            "错误信息: Traceback (most recent call last):\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 197, in <module>\n",
            "    run_transformer_training() \n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 113, in run_transformer_training\n",
            "    train_loader, val_loader, vocab_size, num_classes = get_ag_news_loaders(\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 47, in get_ag_news_loaders\n",
            "    train...\n",
            "验证准确率: 0.00%\n",
            "\n",
            "运行消融实验: single_head - 只用单头注意力\n",
            "警告: 命令执行失败，返回码 1\n",
            "错误信息: Traceback (most recent call last):\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 197, in <module>\n",
            "    run_transformer_training() \n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 113, in run_transformer_training\n",
            "    train_loader, val_loader, vocab_size, num_classes = get_ag_news_loaders(\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 47, in get_ag_news_loaders\n",
            "    train...\n",
            "验证准确率: 0.00%\n",
            "\n",
            "运行消融实验: no_ffn - 移除前馈网络\n",
            "警告: 命令执行失败，返回码 1\n",
            "错误信息: Traceback (most recent call last):\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 197, in <module>\n",
            "    run_transformer_training() \n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 113, in run_transformer_training\n",
            "    train_loader, val_loader, vocab_size, num_classes = get_ag_news_loaders(\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 47, in get_ag_news_loaders\n",
            "    train...\n",
            "验证准确率: 0.00%\n",
            "\n",
            "运行消融实验: freeze_emb - 冻结embedding\n",
            "警告: 命令执行失败，返回码 1\n",
            "错误信息: Traceback (most recent call last):\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 197, in <module>\n",
            "    run_transformer_training() \n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 113, in run_transformer_training\n",
            "    train_loader, val_loader, vocab_size, num_classes = get_ag_news_loaders(\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 47, in get_ag_news_loaders\n",
            "    train...\n",
            "验证准确率: 0.00%\n",
            "\n",
            "运行消融实验: no_dropout - 关闭dropout\n",
            "警告: 命令执行失败，返回码 1\n",
            "错误信息: Traceback (most recent call last):\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 197, in <module>\n",
            "    run_transformer_training() \n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 113, in run_transformer_training\n",
            "    train_loader, val_loader, vocab_size, num_classes = get_ag_news_loaders(\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 47, in get_ag_news_loaders\n",
            "    train...\n",
            "验证准确率: 0.00%\n",
            "\n",
            "运行消融实验: clip_grad - 梯度裁剪\n",
            "警告: 命令执行失败，返回码 1\n",
            "错误信息: Traceback (most recent call last):\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 197, in <module>\n",
            "    run_transformer_training() \n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 113, in run_transformer_training\n",
            "    train_loader, val_loader, vocab_size, num_classes = get_ag_news_loaders(\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 47, in get_ag_news_loaders\n",
            "    train...\n",
            "验证准确率: 0.00%\n"
          ]
        }
      ],
      "source": [
        "# 运行各种消融实验\n",
        "descriptions = {\n",
        "    \"no_pe\": \"关闭位置编码\",\n",
        "    \"single_head\": \"只用单头注意力\",\n",
        "    \"no_ffn\": \"移除前馈网络\",\n",
        "    \"freeze_emb\": \"冻结embedding\",\n",
        "    \"no_dropout\": \"关闭dropout\",\n",
        "    \"clip_grad\": \"梯度裁剪\"\n",
        "}\n",
        "\n",
        "for ablation in ablations:\n",
        "    print(f\"\\n运行消融实验: {ablation} - {descriptions[ablation]}\")\n",
        "    try:\n",
        "        cmd = [\n",
        "            python_executable, \n",
        "            os.path.join(project_root, \"train\", \"train_transformer.py\"),\n",
        "            \"--epochs\", \"3\",\n",
        "            \"--batch-size\", \"64\",\n",
        "            \"--embed-dim\", str(embed_dim),\n",
        "            \"--num-heads\", str(num_heads),\n",
        "            \"--lr\", str(lr),\n",
        "            \"--ablation\", ablation\n",
        "        ]\n",
        "        # 设置环境变量，确保脚本可以找到项目模块\n",
        "        env = os.environ.copy()\n",
        "        env[\"PYTHONPATH\"] = project_root\n",
        "        \n",
        "        process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, env=env)\n",
        "        stdout, stderr = process.communicate()\n",
        "        \n",
        "        if process.returncode != 0:\n",
        "            print(f\"警告: 命令执行失败，返回码 {process.returncode}\")\n",
        "            print(f\"错误信息: {stderr[:500]}...\")\n",
        "            val_acc = 0\n",
        "        else:\n",
        "            val_acc = parse_output(stdout)\n",
        "            if val_acc is None:\n",
        "                val_acc = 0\n",
        "                print(\"无法解析验证准确率，使用默认值 0\")\n",
        "        \n",
        "        ablation_results.append({\n",
        "            \"ablation\": ablation,\n",
        "            \"description\": descriptions[ablation],\n",
        "            \"val_acc\": val_acc\n",
        "        })\n",
        "        print(f\"验证准确率: {val_acc:.2f}%\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"运行消融实验 {ablation} 时出错: {e}\")\n",
        "        # 添加一个包含默认值的结果\n",
        "        ablation_results.append({\n",
        "            \"ablation\": ablation,\n",
        "            \"description\": descriptions[ablation],\n",
        "            \"val_acc\": 0\n",
        "        })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "运行基准模型（无消融）...\n",
            "警告: 命令执行失败，返回码 1\n",
            "错误信息: Traceback (most recent call last):\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 197, in <module>\n",
            "    run_transformer_training() \n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 113, in run_transformer_training\n",
            "    train_loader, val_loader, vocab_size, num_classes = get_ag_news_loaders(\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 47, in get_ag_news_loaders\n",
            "    train...\n",
            "基准模型验证准确率: 0.00%\n"
          ]
        }
      ],
      "source": [
        "# 确保 project_root 已定义\n",
        "if 'project_root' not in locals():\n",
        "    project_root = os.path.abspath('..')\n",
        "    if project_root not in sys.path:\n",
        "        sys.path.insert(0, project_root)\n",
        "    os.environ[\"PYTHONPATH\"] = project_root\n",
        "\n",
        "# 先运行一次基础模型（无消融）作为对照\n",
        "print(\"运行基准模型（无消融）...\")\n",
        "try:\n",
        "    cmd = [\n",
        "        \"python\", \"../train/train_transformer.py\",\n",
        "        \"--epochs\", \"3\",\n",
        "        \"--batch-size\", \"64\",\n",
        "        \"--embed-dim\", str(embed_dim),\n",
        "        \"--num-heads\", str(num_heads),\n",
        "        \"--lr\", str(lr)\n",
        "    ]\n",
        "    # 设置环境变量，确保脚本可以找到项目模块\n",
        "    env = os.environ.copy()\n",
        "    env[\"PYTHONPATH\"] = project_root  # 使用前面定义的project_root\n",
        "    process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, env=env)\n",
        "    stdout, stderr = process.communicate()\n",
        "    \n",
        "    if process.returncode != 0:\n",
        "        print(f\"警告: 命令执行失败，返回码 {process.returncode}\")\n",
        "        print(f\"错误信息: {stderr[:500]}...\")\n",
        "        val_acc = 0\n",
        "    else:\n",
        "        val_acc = parse_output(stdout)\n",
        "        if val_acc is None:\n",
        "            val_acc = 0\n",
        "            print(\"无法解析验证准确率，使用默认值 0\")\n",
        "    \n",
        "    ablation_results.append({\n",
        "        \"ablation\": \"baseline\",\n",
        "        \"description\": \"基准模型（无消融）\",\n",
        "        \"val_acc\": val_acc\n",
        "    })\n",
        "    print(f\"基准模型验证准确率: {val_acc:.2f}%\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"运行基准模型时出错: {e}\")\n",
        "    # 添加一个包含默认值的结果，以便后续代码可以继续执行\n",
        "    ablation_results.append({\n",
        "        \"ablation\": \"baseline\",\n",
        "        \"description\": \"基准模型（无消融）\",\n",
        "        \"val_acc\": 0\n",
        "    })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "运行消融实验: no_pe - 关闭位置编码\n",
            "警告: 命令执行失败，返回码 1\n",
            "错误信息: Traceback (most recent call last):\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 197, in <module>\n",
            "    run_transformer_training() \n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 113, in run_transformer_training\n",
            "    train_loader, val_loader, vocab_size, num_classes = get_ag_news_loaders(\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 47, in get_ag_news_loaders\n",
            "    train...\n",
            "验证准确率: 0.00%\n",
            "\n",
            "运行消融实验: single_head - 只用单头注意力\n",
            "警告: 命令执行失败，返回码 1\n",
            "错误信息: Traceback (most recent call last):\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 197, in <module>\n",
            "    run_transformer_training() \n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 113, in run_transformer_training\n",
            "    train_loader, val_loader, vocab_size, num_classes = get_ag_news_loaders(\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 47, in get_ag_news_loaders\n",
            "    train...\n",
            "验证准确率: 0.00%\n",
            "\n",
            "运行消融实验: no_ffn - 移除前馈网络\n",
            "警告: 命令执行失败，返回码 1\n",
            "错误信息: Traceback (most recent call last):\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 197, in <module>\n",
            "    run_transformer_training() \n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 113, in run_transformer_training\n",
            "    train_loader, val_loader, vocab_size, num_classes = get_ag_news_loaders(\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 47, in get_ag_news_loaders\n",
            "    train...\n",
            "验证准确率: 0.00%\n",
            "\n",
            "运行消融实验: freeze_emb - 冻结embedding\n",
            "警告: 命令执行失败，返回码 1\n",
            "错误信息: Traceback (most recent call last):\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 197, in <module>\n",
            "    run_transformer_training() \n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 113, in run_transformer_training\n",
            "    train_loader, val_loader, vocab_size, num_classes = get_ag_news_loaders(\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 47, in get_ag_news_loaders\n",
            "    train...\n",
            "验证准确率: 0.00%\n",
            "\n",
            "运行消融实验: no_dropout - 关闭dropout\n",
            "警告: 命令执行失败，返回码 1\n",
            "错误信息: Traceback (most recent call last):\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 197, in <module>\n",
            "    run_transformer_training() \n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 113, in run_transformer_training\n",
            "    train_loader, val_loader, vocab_size, num_classes = get_ag_news_loaders(\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 47, in get_ag_news_loaders\n",
            "    train...\n",
            "验证准确率: 0.00%\n",
            "\n",
            "运行消融实验: clip_grad - 梯度裁剪\n",
            "警告: 命令执行失败，返回码 1\n",
            "错误信息: Traceback (most recent call last):\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 197, in <module>\n",
            "    run_transformer_training() \n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 113, in run_transformer_training\n",
            "    train_loader, val_loader, vocab_size, num_classes = get_ag_news_loaders(\n",
            "  File \"c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\train\\train_transformer.py\", line 47, in get_ag_news_loaders\n",
            "    train...\n",
            "验证准确率: 0.00%\n"
          ]
        }
      ],
      "source": [
        "# 运行各种消融实验\n",
        "descriptions = {\n",
        "    \"no_pe\": \"关闭位置编码\",\n",
        "    \"single_head\": \"只用单头注意力\",\n",
        "    \"no_ffn\": \"移除前馈网络\",\n",
        "    \"freeze_emb\": \"冻结embedding\",\n",
        "    \"no_dropout\": \"关闭dropout\",\n",
        "    \"clip_grad\": \"梯度裁剪\"\n",
        "}\n",
        "\n",
        "for ablation in ablations:\n",
        "    print(f\"\\n运行消融实验: {ablation} - {descriptions[ablation]}\")\n",
        "    try:\n",
        "        cmd = [\n",
        "            python_executable, \n",
        "            os.path.join(project_root, \"train\", \"train_transformer.py\"),\n",
        "            \"--epochs\", \"3\",\n",
        "            \"--batch-size\", \"64\",\n",
        "            \"--embed-dim\", str(embed_dim),\n",
        "            \"--num-heads\", str(num_heads),\n",
        "            \"--lr\", str(lr),\n",
        "            \"--ablation\", ablation\n",
        "        ]\n",
        "        # 设置环境变量，确保脚本可以找到项目模块\n",
        "        env = os.environ.copy()\n",
        "        env[\"PYTHONPATH\"] = project_root\n",
        "        process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, env=env)\n",
        "        stdout, stderr = process.communicate()\n",
        "        \n",
        "        if process.returncode != 0:\n",
        "            print(f\"警告: 命令执行失败，返回码 {process.returncode}\")\n",
        "            print(f\"错误信息: {stderr[:500]}...\")\n",
        "            val_acc = 0\n",
        "        else:\n",
        "            val_acc = parse_output(stdout)\n",
        "            if val_acc is None:\n",
        "                val_acc = 0\n",
        "                print(\"无法解析验证准确率，使用默认值 0\")\n",
        "        \n",
        "        ablation_results.append({\n",
        "            \"ablation\": ablation,\n",
        "            \"description\": descriptions[ablation],\n",
        "            \"val_acc\": val_acc\n",
        "        })\n",
        "        print(f\"验证准确率: {val_acc:.2f}%\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"运行消融实验 {ablation} 时出错: {e}\")\n",
        "        # 添加一个包含默认值的结果\n",
        "        ablation_results.append({\n",
        "            \"ablation\": ablation,\n",
        "            \"description\": descriptions[ablation],\n",
        "            \"val_acc\": 0\n",
        "        })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ablation</th>\n",
              "      <th>description</th>\n",
              "      <th>val_acc</th>\n",
              "      <th>rel_change</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>baseline</td>\n",
              "      <td>基准模型（无消融）</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>no_pe</td>\n",
              "      <td>关闭位置编码</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>single_head</td>\n",
              "      <td>只用单头注意力</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>no_ffn</td>\n",
              "      <td>移除前馈网络</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>freeze_emb</td>\n",
              "      <td>冻结embedding</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>no_dropout</td>\n",
              "      <td>关闭dropout</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>clip_grad</td>\n",
              "      <td>梯度裁剪</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>baseline</td>\n",
              "      <td>基准模型（无消融）</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>no_pe</td>\n",
              "      <td>关闭位置编码</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>single_head</td>\n",
              "      <td>只用单头注意力</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>no_ffn</td>\n",
              "      <td>移除前馈网络</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>freeze_emb</td>\n",
              "      <td>冻结embedding</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>no_dropout</td>\n",
              "      <td>关闭dropout</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>clip_grad</td>\n",
              "      <td>梯度裁剪</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       ablation  description  val_acc  rel_change\n",
              "0      baseline    基准模型（无消融）        0         NaN\n",
              "1         no_pe       关闭位置编码        0         NaN\n",
              "2   single_head      只用单头注意力        0         NaN\n",
              "3        no_ffn       移除前馈网络        0         NaN\n",
              "4    freeze_emb  冻结embedding        0         NaN\n",
              "5    no_dropout    关闭dropout        0         NaN\n",
              "6     clip_grad         梯度裁剪        0         NaN\n",
              "7      baseline    基准模型（无消融）        0         NaN\n",
              "8         no_pe       关闭位置编码        0         NaN\n",
              "9   single_head      只用单头注意力        0         NaN\n",
              "10       no_ffn       移除前馈网络        0         NaN\n",
              "11   freeze_emb  冻结embedding        0         NaN\n",
              "12   no_dropout    关闭dropout        0         NaN\n",
              "13    clip_grad         梯度裁剪        0         NaN"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 将消融实验结果整理为DataFrame\n",
        "ablation_df = pd.DataFrame(ablation_results)\n",
        "\n",
        "# 计算相对于基准的性能变化百分比\n",
        "# 获取基准值\n",
        "baseline_rows = ablation_df[ablation_df['ablation'] == 'baseline']\n",
        "if len(baseline_rows) > 0:\n",
        "    baseline_acc = list(baseline_rows['val_acc'])[0]\n",
        "else:\n",
        "    baseline_acc = 0\n",
        "ablation_df['rel_change'] = (ablation_df['val_acc'] - baseline_acc) / baseline_acc * 100\n",
        "\n",
        "# 排序并显示结果\n",
        "ablation_sorted = ablation_df.sort_values(by='val_acc', ascending=False)\n",
        "display(ablation_sorted)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "输出目录: c:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\outputs\\transformer\n",
            "PyTorch 版本: 1.13.0+cpu\n",
            "警告: 未找到 torchtext 模块，请安装: pip install torchtext==0.14.0\n",
            "成功导入所需模块\n"
          ]
        }
      ],
      "source": [
        "# 确保环境设置正确\n",
        "import sys\n",
        "import os\n",
        "import torch\n",
        "from pathlib import Path\n",
        "\n",
        "# 设置项目路径\n",
        "project_root = os.path.abspath('..')\n",
        "if project_root not in sys.path:\n",
        "    sys.path.insert(0, project_root)\n",
        "os.environ[\"PYTHONPATH\"] = project_root\n",
        "\n",
        "# 确保输出目录存在\n",
        "output_dir = Path(project_root) / 'outputs' / 'transformer'\n",
        "output_dir.mkdir(parents=True, exist_ok=True)\n",
        "print(f\"输出目录: {output_dir}\")\n",
        "\n",
        "try:\n",
        "    # 检查依赖\n",
        "    print(f\"PyTorch 版本: {torch.__version__}\")\n",
        "    try:\n",
        "        import torchtext\n",
        "        print(f\"torchtext 版本: {torchtext.__version__}\")\n",
        "    except ImportError:\n",
        "        print(\"警告: 未找到 torchtext 模块，请安装: pip install torchtext==0.14.0\")\n",
        "    \n",
        "    # 尝试导入项目模块\n",
        "    from models.transformer import Transformer\n",
        "    from utils.text_dataloader import get_ag_news_dataloader\n",
        "    print(\"成功导入所需模块\")\n",
        "except ImportError as e:\n",
        "    print(f\"导入错误: {e}\")\n",
        "    print(\"请确保 PYTHONPATH 设置正确，并安装所需依赖: pip install torchtext==0.14.0\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:24: UserWarning: Glyph 20851 (\\N{CJK UNIFIED IDEOGRAPH-5173}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:24: UserWarning: Glyph 38381 (\\N{CJK UNIFIED IDEOGRAPH-95ED}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:24: UserWarning: Glyph 20301 (\\N{CJK UNIFIED IDEOGRAPH-4F4D}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:24: UserWarning: Glyph 32622 (\\N{CJK UNIFIED IDEOGRAPH-7F6E}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:24: UserWarning: Glyph 32534 (\\N{CJK UNIFIED IDEOGRAPH-7F16}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:24: UserWarning: Glyph 30721 (\\N{CJK UNIFIED IDEOGRAPH-7801}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:24: UserWarning: Glyph 32467 (\\N{CJK UNIFIED IDEOGRAPH-7ED3}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:24: UserWarning: Glyph 26500 (\\N{CJK UNIFIED IDEOGRAPH-6784}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:24: UserWarning: Glyph 21464 (\\N{CJK UNIFIED IDEOGRAPH-53D8}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:24: UserWarning: Glyph 20307 (\\N{CJK UNIFIED IDEOGRAPH-4F53}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:24: UserWarning: Glyph 30456 (\\N{CJK UNIFIED IDEOGRAPH-76F8}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:24: UserWarning: Glyph 23545 (\\N{CJK UNIFIED IDEOGRAPH-5BF9}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:24: UserWarning: Glyph 20934 (\\N{CJK UNIFIED IDEOGRAPH-51C6}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:24: UserWarning: Glyph 30830 (\\N{CJK UNIFIED IDEOGRAPH-786E}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:24: UserWarning: Glyph 29575 (\\N{CJK UNIFIED IDEOGRAPH-7387}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:24: UserWarning: Glyph 21270 (\\N{CJK UNIFIED IDEOGRAPH-5316}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:24: UserWarning: Glyph 21508 (\\N{CJK UNIFIED IDEOGRAPH-5404}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:24: UserWarning: Glyph 31181 (\\N{CJK UNIFIED IDEOGRAPH-79CD}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:24: UserWarning: Glyph 27169 (\\N{CJK UNIFIED IDEOGRAPH-6A21}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:24: UserWarning: Glyph 22411 (\\N{CJK UNIFIED IDEOGRAPH-578B}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:24: UserWarning: Glyph 24615 (\\N{CJK UNIFIED IDEOGRAPH-6027}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:24: UserWarning: Glyph 33021 (\\N{CJK UNIFIED IDEOGRAPH-80FD}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:24: UserWarning: Glyph 30340 (\\N{CJK UNIFIED IDEOGRAPH-7684}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:24: UserWarning: Glyph 24433 (\\N{CJK UNIFIED IDEOGRAPH-5F71}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:24: UserWarning: Glyph 21709 (\\N{CJK UNIFIED IDEOGRAPH-54CD}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:24: UserWarning: Glyph 20110 (\\N{CJK UNIFIED IDEOGRAPH-4E8E}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:24: UserWarning: Glyph 22522 (\\N{CJK UNIFIED IDEOGRAPH-57FA}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:26: UserWarning: Glyph 30456 (\\N{CJK UNIFIED IDEOGRAPH-76F8}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'ablation_results.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:26: UserWarning: Glyph 23545 (\\N{CJK UNIFIED IDEOGRAPH-5BF9}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'ablation_results.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:26: UserWarning: Glyph 20934 (\\N{CJK UNIFIED IDEOGRAPH-51C6}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'ablation_results.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:26: UserWarning: Glyph 30830 (\\N{CJK UNIFIED IDEOGRAPH-786E}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'ablation_results.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:26: UserWarning: Glyph 29575 (\\N{CJK UNIFIED IDEOGRAPH-7387}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'ablation_results.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:26: UserWarning: Glyph 21464 (\\N{CJK UNIFIED IDEOGRAPH-53D8}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'ablation_results.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:26: UserWarning: Glyph 21270 (\\N{CJK UNIFIED IDEOGRAPH-5316}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'ablation_results.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:26: UserWarning: Glyph 21508 (\\N{CJK UNIFIED IDEOGRAPH-5404}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'ablation_results.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:26: UserWarning: Glyph 31181 (\\N{CJK UNIFIED IDEOGRAPH-79CD}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'ablation_results.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:26: UserWarning: Glyph 32467 (\\N{CJK UNIFIED IDEOGRAPH-7ED3}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'ablation_results.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:26: UserWarning: Glyph 26500 (\\N{CJK UNIFIED IDEOGRAPH-6784}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'ablation_results.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:26: UserWarning: Glyph 20307 (\\N{CJK UNIFIED IDEOGRAPH-4F53}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'ablation_results.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:26: UserWarning: Glyph 27169 (\\N{CJK UNIFIED IDEOGRAPH-6A21}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'ablation_results.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:26: UserWarning: Glyph 22411 (\\N{CJK UNIFIED IDEOGRAPH-578B}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'ablation_results.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:26: UserWarning: Glyph 24615 (\\N{CJK UNIFIED IDEOGRAPH-6027}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'ablation_results.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:26: UserWarning: Glyph 33021 (\\N{CJK UNIFIED IDEOGRAPH-80FD}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'ablation_results.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:26: UserWarning: Glyph 30340 (\\N{CJK UNIFIED IDEOGRAPH-7684}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'ablation_results.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:26: UserWarning: Glyph 24433 (\\N{CJK UNIFIED IDEOGRAPH-5F71}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'ablation_results.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:26: UserWarning: Glyph 21709 (\\N{CJK UNIFIED IDEOGRAPH-54CD}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'ablation_results.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:26: UserWarning: Glyph 20110 (\\N{CJK UNIFIED IDEOGRAPH-4E8E}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'ablation_results.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:26: UserWarning: Glyph 22522 (\\N{CJK UNIFIED IDEOGRAPH-57FA}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'ablation_results.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:26: UserWarning: Glyph 20851 (\\N{CJK UNIFIED IDEOGRAPH-5173}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'ablation_results.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:26: UserWarning: Glyph 38381 (\\N{CJK UNIFIED IDEOGRAPH-95ED}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'ablation_results.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:26: UserWarning: Glyph 20301 (\\N{CJK UNIFIED IDEOGRAPH-4F4D}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'ablation_results.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:26: UserWarning: Glyph 32622 (\\N{CJK UNIFIED IDEOGRAPH-7F6E}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'ablation_results.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:26: UserWarning: Glyph 32534 (\\N{CJK UNIFIED IDEOGRAPH-7F16}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'ablation_results.png', dpi=300, bbox_inches='tight')\n",
            "C:\\Users\\WHY\\AppData\\Local\\Temp\\ipykernel_4080\\3346838966.py:26: UserWarning: Glyph 30721 (\\N{CJK UNIFIED IDEOGRAPH-7801}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(output_dir / 'ablation_results.png', dpi=300, bbox_inches='tight')\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 30456 (\\N{CJK UNIFIED IDEOGRAPH-76F8}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 23545 (\\N{CJK UNIFIED IDEOGRAPH-5BF9}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 20934 (\\N{CJK UNIFIED IDEOGRAPH-51C6}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 30830 (\\N{CJK UNIFIED IDEOGRAPH-786E}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 29575 (\\N{CJK UNIFIED IDEOGRAPH-7387}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 21464 (\\N{CJK UNIFIED IDEOGRAPH-53D8}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 21270 (\\N{CJK UNIFIED IDEOGRAPH-5316}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 21508 (\\N{CJK UNIFIED IDEOGRAPH-5404}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 31181 (\\N{CJK UNIFIED IDEOGRAPH-79CD}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 32467 (\\N{CJK UNIFIED IDEOGRAPH-7ED3}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 26500 (\\N{CJK UNIFIED IDEOGRAPH-6784}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 20307 (\\N{CJK UNIFIED IDEOGRAPH-4F53}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 27169 (\\N{CJK UNIFIED IDEOGRAPH-6A21}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 22411 (\\N{CJK UNIFIED IDEOGRAPH-578B}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 24615 (\\N{CJK UNIFIED IDEOGRAPH-6027}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 33021 (\\N{CJK UNIFIED IDEOGRAPH-80FD}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 30340 (\\N{CJK UNIFIED IDEOGRAPH-7684}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 24433 (\\N{CJK UNIFIED IDEOGRAPH-5F71}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 21709 (\\N{CJK UNIFIED IDEOGRAPH-54CD}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 20110 (\\N{CJK UNIFIED IDEOGRAPH-4E8E}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 22522 (\\N{CJK UNIFIED IDEOGRAPH-57FA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 20851 (\\N{CJK UNIFIED IDEOGRAPH-5173}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 38381 (\\N{CJK UNIFIED IDEOGRAPH-95ED}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 20301 (\\N{CJK UNIFIED IDEOGRAPH-4F4D}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 32622 (\\N{CJK UNIFIED IDEOGRAPH-7F6E}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 32534 (\\N{CJK UNIFIED IDEOGRAPH-7F16}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "c:\\Users\\WHY\\anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 30721 (\\N{CJK UNIFIED IDEOGRAPH-7801}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 可视化消融实验结果\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# 不包含baseline的数据\n",
        "plot_df = ablation_df[ablation_df['ablation'] != 'baseline'].copy()\n",
        "\n",
        "# 根据相对变化排序 (这将正常工作，尽管IDE可能显示警告)\n",
        "# sort_values是pandas的标准方法，运行时不会出错\n",
        "plot_df = plot_df.sort_values('rel_change')\n",
        "\n",
        "# 创建柱状图\n",
        "bars = plt.bar(plot_df['description'], plot_df['rel_change'])\n",
        "\n",
        "# 为负值设置不同颜色\n",
        "for i, v in enumerate(plot_df['rel_change']):\n",
        "    if v < 0:\n",
        "        bars[i].set_alpha(0.7)\n",
        "\n",
        "plt.axhline(y=0, color='r', linestyle='-', alpha=0.3)\n",
        "plt.title(f\"各种结构变体对模型性能的影响 (相对于基准 {baseline_acc:.2f}%)\", fontsize=14)\n",
        "plt.xlabel(\"结构变体\")\n",
        "plt.ylabel(\"相对准确率变化 (%)\")\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.savefig(output_dir / 'ablation_results.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Attention 可视化\n",
        "\n",
        "加载最高分模型，选择一条验证集样本，可视化第1层第1个头的注意力热力图。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('..')\n",
        "import torch\n",
        "from models.transformer import Transformer\n",
        "from utils.text_dataloader import get_ag_news_dataloader\n",
        "from pathlib import Path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "需要安装 torchtext 才能使用 AG_NEWS 数据集",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[22], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 加载最佳模型\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# 获取验证数据加载器\u001b[39;00m\n\u001b[0;32m      3\u001b[0m data_dir \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m val_loader, vocab, vocab_size, num_classes \u001b[38;5;241m=\u001b[39m \u001b[43mget_ag_news_dataloader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 单条样本\u001b[39;49;00m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# 限制长度以便可视化\u001b[39;49;00m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# 根据最佳超参数创建模型\u001b[39;00m\n\u001b[0;32m     12\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\WHY\\Projects\\Personal\\PyTorch_Learning\\utils\\text_dataloader.py:94\u001b[0m, in \u001b[0;36mget_ag_news_dataloader\u001b[1;34m(batch_size, max_len, train, root)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;124;03m获取 AG_NEWS 数据集的 DataLoader。\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;124;03m- num_classes: 类别数量 (4 for AG_NEWS)\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m TORCHTEXT_AVAILABLE:\n\u001b[1;32m---> 94\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m需要安装 torchtext 才能使用 AG_NEWS 数据集\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     96\u001b[0m \u001b[38;5;66;03m# 确保数据目录存在\u001b[39;00m\n\u001b[0;32m     97\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(root, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[1;31mImportError\u001b[0m: 需要安装 torchtext 才能使用 AG_NEWS 数据集"
          ]
        }
      ],
      "source": [
        "# 加载最佳模型\n",
        "# 获取验证数据加载器\n",
        "data_dir = Path(\"../data\")\n",
        "val_loader, vocab, vocab_size, num_classes = get_ag_news_dataloader(\n",
        "    batch_size=1,  # 单条样本\n",
        "    max_len=128,   # 限制长度以便可视化\n",
        "    train=False,\n",
        "    root=str(data_dir)\n",
        ")\n",
        "\n",
        "# 根据最佳超参数创建模型\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = Transformer(\n",
        "    vocab_size=vocab_size,\n",
        "    embed_dim=embed_dim,\n",
        "    num_heads=num_heads,\n",
        "    hidden_dim=embed_dim*4,  # 标准Transformer通常使用4倍embed_dim作为FFN隐藏层\n",
        "    num_layers=3,\n",
        "    num_classes=num_classes\n",
        ")\n",
        "\n",
        "# 加载最佳检查点\n",
        "best_model_path = Path(\"../outputs/transformer/transformer_best.pth\")\n",
        "if best_model_path.exists():\n",
        "    model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
        "    print(f\"已加载最佳模型: {best_model_path}\")\n",
        "else:\n",
        "    print(f\"找不到最佳模型文件，使用未训练模型\")\n",
        "\n",
        "model = model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 提取单个Transformer层注意力权重的钩子函数\n",
        "class AttentionHook:\n",
        "    def __init__(self):\n",
        "        self.attn_weights = None\n",
        "        \n",
        "    def __call__(self, module, module_input, module_output):\n",
        "        # PyTorch TransformerEncoder层的attention weights在运行时不保存\n",
        "        # 我们需要修改模型结构以访问它们\n",
        "        # 这里仅为示例，实际使用时需调整\n",
        "        self.attn_weights = None  # 稍后会在前向传播中手动提取\n",
        "\n",
        "\n",
        "# 修改Transformer模型来返回注意力权重\n",
        "def forward_with_attention(model, x, src_key_padding_mask=None):\n",
        "    \"\"\"修改的前向传播，返回注意力权重\"\"\"\n",
        "    # 词嵌入 [batch_size, seq_len] -> [batch_size, seq_len, embed_dim]\n",
        "    embedded = model.embedding(x)\n",
        "    \n",
        "    # 添加位置编码\n",
        "    embedded = model.pos_encoder(embedded)\n",
        "    \n",
        "    # 我们需要访问TransformerEncoder的第一层的第一个注意力头\n",
        "    # 由于PyTorch没有直接暴露这个API，我们需要手动添加钩子或修改模型\n",
        "    # 这里是一个近似方法，实际实现可能需要更深入地修改模型\n",
        "    \n",
        "    # 使用第一个编码器层的self-attention模块\n",
        "    first_layer = model.transformer_encoder.layers[0]\n",
        "    \n",
        "    # 1. 应用自注意力，并保存注意力权重\n",
        "    # 这部分逻辑通常在TransformerEncoderLayer的内部\n",
        "    q = first_layer.self_attn.q_proj(embedded)\n",
        "    k = first_layer.self_attn.k_proj(embedded)\n",
        "    v = first_layer.self_attn.v_proj(embedded)\n",
        "    \n",
        "    # 重塑为多头形式\n",
        "    batch_size, seq_len = embedded.shape[0], embedded.shape[1]\n",
        "    head_dim = model.transformer_encoder.layers[0].self_attn.head_dim\n",
        "    num_heads = model.transformer_encoder.layers[0].self_attn.num_heads\n",
        "    \n",
        "    q = q.view(batch_size, seq_len, num_heads, head_dim).transpose(1, 2)\n",
        "    k = k.view(batch_size, seq_len, num_heads, head_dim).transpose(1, 2)\n",
        "    v = v.view(batch_size, seq_len, num_heads, head_dim).transpose(1, 2)\n",
        "    \n",
        "    # 计算注意力分数\n",
        "    scores = torch.matmul(q, k.transpose(-2, -1)) / (head_dim ** 0.5)\n",
        "    \n",
        "    # 应用掩码（如果有）\n",
        "    if src_key_padding_mask is not None:\n",
        "        # 扩展掩码以匹配分数的形状\n",
        "        mask = src_key_padding_mask.unsqueeze(1).unsqueeze(2)\n",
        "        scores = scores.masked_fill(mask, float(\"-inf\"))\n",
        "    \n",
        "    # 应用softmax得到注意力权重\n",
        "    attn_weights = torch.nn.functional.softmax(scores, dim=-1)\n",
        "    \n",
        "    # 提取第一个头的注意力权重\n",
        "    first_head_attn = attn_weights[0, 0].cpu().detach()\n",
        "    \n",
        "    # 继续常规前向传播\n",
        "    # 由于我们不需要完整的前向传播结果，这里简化了步骤\n",
        "    \n",
        "    return first_head_attn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 选择一条验证样本\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    # 获取一个批次\n",
        "    for tokens, labels, masks in val_loader:\n",
        "        tokens, labels, masks = tokens.to(device), labels.to(device), masks.to(device)\n",
        "        \n",
        "        # 使用修改后的前向传播函数获取注意力权重\n",
        "        attention_weights = forward_with_attention(model, tokens, src_key_padding_mask=masks)\n",
        "        \n",
        "        # 获取真实标记（而不是填充标记）\n",
        "        valid_seq_len = (~masks[0]).sum().item()\n",
        "        \n",
        "        # 可视化注意力热力图\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        \n",
        "        # 只显示有效的标记（不显示填充标记）\n",
        "        valid_attn = attention_weights[:valid_seq_len, :valid_seq_len]\n",
        "        \n",
        "        # 创建热力图\n",
        "        sns.heatmap(valid_attn, cmap=\"viridis\")\n",
        "        plt.title(f\"第1层第1个头的Self-Attention热力图 (类别: {labels.item()+1})\")\n",
        "        plt.xlabel(\"Token位置\")\n",
        "        plt.ylabel(\"Token位置\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(output_dir / 'attention_heatmap.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "        \n",
        "        # 一条样本就够了\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 结论总结\n",
        "\n",
        "1. **超参数实验结论**\n",
        "   - 最佳超参数组合及其性能表现\n",
        "   - embedding维度与head数量的关系\n",
        "   - 学习率对不同模型规模的影响\n",
        "\n",
        "2. **结构变体实验结论**\n",
        "   - 各组件对模型性能的影响排序\n",
        "   - 哪些组件是必不可少的，哪些影响较小\n",
        "\n",
        "3. **注意力可视化分析**\n",
        "   - 模型关注了哪些位置的token\n",
        "   - 是否存在明显的注意力模式\n",
        "\n",
        "4. **TODO 与改进方向**\n",
        "   - 尝试更多超参数组合\n",
        "   - 增加序列长度或批量大小\n",
        "   - 尝试不同的位置编码方案\n",
        "   - 探索预训练与微调策略\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "dl",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
